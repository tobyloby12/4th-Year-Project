{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from time import sleep\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import optical_network_game.game_gym\n",
    "importlib.reload(optical_network_game.game_gym)\n",
    "from optical_network_game.game_gym import *\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common import results_plotter\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy, plot_results\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq:\n",
    "    :param log_dir: Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: Verbosity level.\n",
    "    \"\"\"\n",
    "    def __init__(self, check_freq: int, log_dir: str, verbose: int = 1):\n",
    "        super(SaveOnBestTrainingRewardCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, 'best_model')\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        # Create folder if needed\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "\n",
    "          # Retrieve training reward\n",
    "          x, y = ts2xy(load_results(self.log_dir), 'timesteps')\n",
    "          if len(x) > 0:\n",
    "              # Mean training reward over the last 100 episodes\n",
    "              mean_reward = np.mean(y[-100:])\n",
    "              if self.verbose > 0:\n",
    "                print(f\"Num timesteps: {self.num_timesteps}\")\n",
    "                print(f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\")\n",
    "\n",
    "              # New best model, you could save the agent here\n",
    "              if mean_reward > self.best_mean_reward:\n",
    "                  self.best_mean_reward = mean_reward\n",
    "                  # Example for saving best model\n",
    "                  if self.verbose > 0:\n",
    "                    print(f\"Saving new best model to {self.save_path}\")\n",
    "                  self.model.save(self.save_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Create log dir\n",
    "log_dir = os.path.join(os.getcwd(), \"tmp/\")\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# Create the callback: check every 1000 steps\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=10000, log_dir=log_dir)\n",
    "\n",
    "# create model\n",
    "\n",
    "nodeList, linkList = createTestTopology()\n",
    "requestList = generateRequests(nodeList, 30)\n",
    "\n",
    "user = User()\n",
    "env = game_gym(nodeList, linkList, requestList, user)\n",
    "eveon = Monitor(env, log_dir)\n",
    "\n",
    "# check_env(eveon, warn=True)\n",
    "model = DQN('MlpPolicy', eveon, verbose=1, buffer_size=10000, device='cuda', learning_starts=10000, exploration_fraction=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "Total reward for this episode is -14226\n",
      "(256, 256, 3)\n",
      "Num timesteps: 9203\n",
      "Best mean reward: -inf - Last mean reward per episode: -38611068.00\n",
      "Saving new best model to c:\\Users\\tkate\\Desktop\\Year 4\\project\\Game part\\4th-Year-Project\\tmp/best_model\n",
      "Total reward for this episode is -6935\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5087\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5634\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 4.3e+03   |\n",
      "|    ep_rew_mean      | -1.42e+07 |\n",
      "|    exploration_rate | 0.909     |\n",
      "| time/               |           |\n",
      "|    episodes         | 4         |\n",
      "|    fps              | 93        |\n",
      "|    time_elapsed     | 183       |\n",
      "|    total_timesteps  | 17213     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 2.64e+03  |\n",
      "|    n_updates        | 1803      |\n",
      "-----------------------------------\n",
      "Num timesteps: 19203\n",
      "Best mean reward: -38611068.00 - Last mean reward per episode: -14244577.50\n",
      "Saving new best model to c:\\Users\\tkate\\Desktop\\Year 4\\project\\Game part\\4th-Year-Project\\tmp/best_model\n",
      "Total reward for this episode is -6847\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5376\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -3894\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -4331\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 3.41e+03  |\n",
      "|    ep_rew_mean      | -9.11e+06 |\n",
      "|    exploration_rate | 0.856     |\n",
      "| time/               |           |\n",
      "|    episodes         | 8         |\n",
      "|    fps              | 71        |\n",
      "|    time_elapsed     | 378       |\n",
      "|    total_timesteps  | 27242     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.32e+03  |\n",
      "|    n_updates        | 4310      |\n",
      "-----------------------------------\n",
      "Num timesteps: 29203\n",
      "Best mean reward: -14244577.50 - Last mean reward per episode: -9110540.12\n",
      "Saving new best model to c:\\Users\\tkate\\Desktop\\Year 4\\project\\Game part\\4th-Year-Project\\tmp/best_model\n",
      "Total reward for this episode is -6409\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6526\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6166\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -4538\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 3.12e+03  |\n",
      "|    ep_rew_mean      | -7.79e+06 |\n",
      "|    exploration_rate | 0.803     |\n",
      "| time/               |           |\n",
      "|    episodes         | 12        |\n",
      "|    fps              | 65        |\n",
      "|    time_elapsed     | 570       |\n",
      "|    total_timesteps  | 37416     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 2.1e+03   |\n",
      "|    n_updates        | 6853      |\n",
      "-----------------------------------\n",
      "Num timesteps: 39203\n",
      "Best mean reward: -9110540.12 - Last mean reward per episode: -7789565.42\n",
      "Saving new best model to c:\\Users\\tkate\\Desktop\\Year 4\\project\\Game part\\4th-Year-Project\\tmp/best_model\n",
      "Total reward for this episode is -4074\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5525\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5908\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6384\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 2.98e+03  |\n",
      "|    ep_rew_mean      | -6.94e+06 |\n",
      "|    exploration_rate | 0.748     |\n",
      "| time/               |           |\n",
      "|    episodes         | 16        |\n",
      "|    fps              | 62        |\n",
      "|    time_elapsed     | 763       |\n",
      "|    total_timesteps  | 47673     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.63e+03  |\n",
      "|    n_updates        | 9418      |\n",
      "-----------------------------------\n",
      "Num timesteps: 49203\n",
      "Best mean reward: -7789565.42 - Last mean reward per episode: -6935957.69\n",
      "Saving new best model to c:\\Users\\tkate\\Desktop\\Year 4\\project\\Game part\\4th-Year-Project\\tmp/best_model\n",
      "Total reward for this episode is -5424\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5761\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -4862\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5837\n",
      "(256, 256, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.89e+03 |\n",
      "|    ep_rew_mean      | -6.3e+06 |\n",
      "|    exploration_rate | 0.695    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 60       |\n",
      "|    time_elapsed     | 959      |\n",
      "|    total_timesteps  | 57781    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.35e+03 |\n",
      "|    n_updates        | 11945    |\n",
      "----------------------------------\n",
      "Num timesteps: 59203\n",
      "Best mean reward: -6935957.69 - Last mean reward per episode: -6298336.35\n",
      "Saving new best model to c:\\Users\\tkate\\Desktop\\Year 4\\project\\Game part\\4th-Year-Project\\tmp/best_model\n",
      "Total reward for this episode is -6046\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -9879\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5994\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6113\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 2.82e+03  |\n",
      "|    ep_rew_mean      | -6.23e+06 |\n",
      "|    exploration_rate | 0.642     |\n",
      "| time/               |           |\n",
      "|    episodes         | 24        |\n",
      "|    fps              | 58        |\n",
      "|    time_elapsed     | 1152      |\n",
      "|    total_timesteps  | 67777     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.36e+03  |\n",
      "|    n_updates        | 14444     |\n",
      "-----------------------------------\n",
      "Num timesteps: 69203\n",
      "Best mean reward: -6298336.35 - Last mean reward per episode: -6234395.25\n",
      "Saving new best model to c:\\Users\\tkate\\Desktop\\Year 4\\project\\Game part\\4th-Year-Project\\tmp/best_model\n",
      "Total reward for this episode is -5542\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5762\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6465\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6725\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 2.8e+03   |\n",
      "|    ep_rew_mean      | -5.94e+06 |\n",
      "|    exploration_rate | 0.586     |\n",
      "| time/               |           |\n",
      "|    episodes         | 28        |\n",
      "|    fps              | 58        |\n",
      "|    time_elapsed     | 1348      |\n",
      "|    total_timesteps  | 78460     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.7e+03   |\n",
      "|    n_updates        | 17114     |\n",
      "-----------------------------------\n",
      "Num timesteps: 79203\n",
      "Best mean reward: -6234395.25 - Last mean reward per episode: -5942231.00\n",
      "Saving new best model to c:\\Users\\tkate\\Desktop\\Year 4\\project\\Game part\\4th-Year-Project\\tmp/best_model\n",
      "Total reward for this episode is -6156\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6228\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -4799\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5607\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 2.77e+03  |\n",
      "|    ep_rew_mean      | -5.71e+06 |\n",
      "|    exploration_rate | 0.532     |\n",
      "| time/               |           |\n",
      "|    episodes         | 32        |\n",
      "|    fps              | 57        |\n",
      "|    time_elapsed     | 1542      |\n",
      "|    total_timesteps  | 88734     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.73e+03  |\n",
      "|    n_updates        | 19683     |\n",
      "-----------------------------------\n",
      "Num timesteps: 89203\n",
      "Best mean reward: -5942231.00 - Last mean reward per episode: -5709882.44\n",
      "Saving new best model to c:\\Users\\tkate\\Desktop\\Year 4\\project\\Game part\\4th-Year-Project\\tmp/best_model\n",
      "Total reward for this episode is -8597\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5960\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6449\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6526\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 2.75e+03  |\n",
      "|    ep_rew_mean      | -5.65e+06 |\n",
      "|    exploration_rate | 0.477     |\n",
      "| time/               |           |\n",
      "|    episodes         | 36        |\n",
      "|    fps              | 57        |\n",
      "|    time_elapsed     | 1739      |\n",
      "|    total_timesteps  | 99161     |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.94e+03  |\n",
      "|    n_updates        | 22290     |\n",
      "-----------------------------------\n",
      "Num timesteps: 99203\n",
      "Best mean reward: -5709882.44 - Last mean reward per episode: -5652770.78\n",
      "Saving new best model to c:\\Users\\tkate\\Desktop\\Year 4\\project\\Game part\\4th-Year-Project\\tmp/best_model\n",
      "Total reward for this episode is -4620\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -7116\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6346\n",
      "(256, 256, 3)\n",
      "Num timesteps: 109203\n",
      "Best mean reward: -5652770.78 - Last mean reward per episode: -5574010.10\n",
      "Saving new best model to c:\\Users\\tkate\\Desktop\\Year 4\\project\\Game part\\4th-Year-Project\\tmp/best_model\n",
      "Total reward for this episode is -6457\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 2.74e+03  |\n",
      "|    ep_rew_mean      | -5.54e+06 |\n",
      "|    exploration_rate | 0.422     |\n",
      "| time/               |           |\n",
      "|    episodes         | 40        |\n",
      "|    fps              | 56        |\n",
      "|    time_elapsed     | 1935      |\n",
      "|    total_timesteps  | 109463    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 2.17e+03  |\n",
      "|    n_updates        | 24865     |\n",
      "-----------------------------------\n",
      "Total reward for this episode is -5041\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6528\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5311\n",
      "(256, 256, 3)\n",
      "Num timesteps: 119203\n",
      "Best mean reward: -5574010.10 - Last mean reward per episode: -5470274.86\n",
      "Saving new best model to c:\\Users\\tkate\\Desktop\\Year 4\\project\\Game part\\4th-Year-Project\\tmp/best_model\n",
      "Total reward for this episode is -4622\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 2.72e+03  |\n",
      "|    ep_rew_mean      | -5.43e+06 |\n",
      "|    exploration_rate | 0.369     |\n",
      "| time/               |           |\n",
      "|    episodes         | 44        |\n",
      "|    fps              | 56        |\n",
      "|    time_elapsed     | 2128      |\n",
      "|    total_timesteps  | 119569    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.94e+03  |\n",
      "|    n_updates        | 27392     |\n",
      "-----------------------------------\n",
      "Total reward for this episode is -8386\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -4687\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5537\n",
      "(256, 256, 3)\n",
      "Num timesteps: 129203\n",
      "Best mean reward: -5470274.86 - Last mean reward per episode: -5433921.96\n",
      "Saving new best model to c:\\Users\\tkate\\Desktop\\Year 4\\project\\Game part\\4th-Year-Project\\tmp/best_model\n",
      "Total reward for this episode is -5655\n",
      "(256, 256, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.7e+03  |\n",
      "|    ep_rew_mean      | -5.4e+06 |\n",
      "|    exploration_rate | 0.317    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 55       |\n",
      "|    time_elapsed     | 2322     |\n",
      "|    total_timesteps  | 129456   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.11e+03 |\n",
      "|    n_updates        | 29863    |\n",
      "----------------------------------\n",
      "Total reward for this episode is -5431\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6067\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6808\n",
      "(256, 256, 3)\n",
      "Num timesteps: 139203\n",
      "Best mean reward: -5433921.96 - Last mean reward per episode: -5353134.78\n",
      "Saving new best model to c:\\Users\\tkate\\Desktop\\Year 4\\project\\Game part\\4th-Year-Project\\tmp/best_model\n",
      "Total reward for this episode is -7022\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 2.68e+03  |\n",
      "|    ep_rew_mean      | -5.34e+06 |\n",
      "|    exploration_rate | 0.265     |\n",
      "| time/               |           |\n",
      "|    episodes         | 52        |\n",
      "|    fps              | 55        |\n",
      "|    time_elapsed     | 2517      |\n",
      "|    total_timesteps  | 139209    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.84e+03  |\n",
      "|    n_updates        | 32302     |\n",
      "-----------------------------------\n",
      "Total reward for this episode is -6465\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5807\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5423\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -7441\n",
      "(256, 256, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 2.65e+03 |\n",
      "|    ep_rew_mean      | -5.3e+06 |\n",
      "|    exploration_rate | 0.216    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 54       |\n",
      "|    time_elapsed     | 2713     |\n",
      "|    total_timesteps  | 148494   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.83e+03 |\n",
      "|    n_updates        | 34623    |\n",
      "----------------------------------\n",
      "Num timesteps: 149203\n",
      "Best mean reward: -5353134.78 - Last mean reward per episode: -5296347.73\n",
      "Saving new best model to c:\\Users\\tkate\\Desktop\\Year 4\\project\\Game part\\4th-Year-Project\\tmp/best_model\n",
      "Total reward for this episode is -7196\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -8212\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -7553\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -14530\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 2.64e+03  |\n",
      "|    ep_rew_mean      | -5.58e+06 |\n",
      "|    exploration_rate | 0.165     |\n",
      "| time/               |           |\n",
      "|    episodes         | 60        |\n",
      "|    fps              | 54        |\n",
      "|    time_elapsed     | 2909      |\n",
      "|    total_timesteps  | 158138    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 3.24e+03  |\n",
      "|    n_updates        | 37034     |\n",
      "-----------------------------------\n",
      "Num timesteps: 159203\n",
      "Best mean reward: -5296347.73 - Last mean reward per episode: -5575219.78\n",
      "Total reward for this episode is -5782\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5983\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6682\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6446\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 2.62e+03  |\n",
      "|    ep_rew_mean      | -5.52e+06 |\n",
      "|    exploration_rate | 0.115     |\n",
      "| time/               |           |\n",
      "|    episodes         | 64        |\n",
      "|    fps              | 53        |\n",
      "|    time_elapsed     | 3106      |\n",
      "|    total_timesteps  | 167697    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.44e+03  |\n",
      "|    n_updates        | 39424     |\n",
      "-----------------------------------\n",
      "Num timesteps: 169203\n",
      "Best mean reward: -5296347.73 - Last mean reward per episode: -5515113.77\n",
      "Total reward for this episode is -6497\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -5730\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6737\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6384\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 2.6e+03   |\n",
      "|    ep_rew_mean      | -5.44e+06 |\n",
      "|    exploration_rate | 0.0678    |\n",
      "| time/               |           |\n",
      "|    episodes         | 68        |\n",
      "|    fps              | 53        |\n",
      "|    time_elapsed     | 3302      |\n",
      "|    total_timesteps  | 176633    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.71e+03  |\n",
      "|    n_updates        | 41658     |\n",
      "-----------------------------------\n",
      "Total reward for this episode is -6664\n",
      "(256, 256, 3)\n",
      "Num timesteps: 179203\n",
      "Best mean reward: -5296347.73 - Last mean reward per episode: -5424266.64\n",
      "Total reward for this episode is -7482\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -8081\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -8026\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 2.57e+03  |\n",
      "|    ep_rew_mean      | -5.42e+06 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 72        |\n",
      "|    fps              | 52        |\n",
      "|    time_elapsed     | 3498      |\n",
      "|    total_timesteps  | 184986    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 1.98e+03  |\n",
      "|    n_updates        | 43746     |\n",
      "-----------------------------------\n",
      "Total reward for this episode is -7262\n",
      "(256, 256, 3)\n",
      "Num timesteps: 189203\n",
      "Best mean reward: -5296347.73 - Last mean reward per episode: -5410965.30\n",
      "Total reward for this episode is -7278\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6721\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -6643\n",
      "(256, 256, 3)\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 2.55e+03  |\n",
      "|    ep_rew_mean      | -5.38e+06 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 76        |\n",
      "|    fps              | 52        |\n",
      "|    time_elapsed     | 3694      |\n",
      "|    total_timesteps  | 193646    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 2.54e+03  |\n",
      "|    n_updates        | 45911     |\n",
      "-----------------------------------\n",
      "Total reward for this episode is -7339\n",
      "(256, 256, 3)\n",
      "Total reward for this episode is -7575\n",
      "(256, 256, 3)\n",
      "Num timesteps: 199203\n",
      "Best mean reward: -5296347.73 - Last mean reward per episode: -5379220.62\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "model.learn(total_timesteps=200000, callback=callback)\n",
    "model.save(\"DQNEveon8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot rewards\n",
    "plot_results([log_dir], 200000, results_plotter.X_TIMESTEPS, \"DQN EON\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "(256, 256, 3)\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Total reward for this episode is -13069.766666666666\n",
      "2\n",
      "-13069.766666666666\n",
      "(256, 256, 3)\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "model = DQN.load(\"DQNeveon8\", env=env, device='cpu')\n",
    "\n",
    "obs = env.reset()\n",
    "while True :\n",
    "    # clear_output(wait=True)\n",
    "    action, states_ = model.predict(obs, deterministic=True)\n",
    "    # action = 6\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    # plt.imshow(obs)\n",
    "    # plt.show()\n",
    "    print(action)\n",
    "    if dones == True:\n",
    "        print(env.reward)\n",
    "\n",
    "        # with open('info.json', 'w') as outfile:\n",
    "        #     json.dump(info, outfile)\n",
    "\n",
    "        env.reset()\n",
    "\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e1680fa3f035ba33798eeb42b0c1edda6a758b70597993f042faeae31b18ae3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('4thYearprojectEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
