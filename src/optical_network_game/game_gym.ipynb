{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optical_network_game.node import *\n",
    "from optical_network_game.link import *\n",
    "from optical_network_game.requests import *\n",
    "from optical_network_game.user import *\n",
    "import gym\n",
    "import pygame, sys\n",
    "from pygame.locals import *\n",
    "from gym import spaces\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import HerReplayBuffer\n",
    "from stable_baselines3.her.goal_selection_strategy import GoalSelectionStrategy\n",
    "\n",
    "import numpy as np\n",
    "# from stable_baselines.common.vec_env import DummyVecEnv\n",
    "# from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3 import A2C\n",
    "import json\n",
    "\n",
    "#additional code added by me just for testing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "#importing IPython's display module to plot images\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython: from IPython import display\n",
    "from itertools import count\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class game_gym(gym.Env):\n",
    "    '''\n",
    "    Elastic Optical Network (EON) game made into an OpenAI gym environment for easier interface with RL algorithms.\n",
    "    '''\n",
    "    # set game window width and height\n",
    "    WINDOWWIDTH = 1000\n",
    "    WINDOWHEIGHT = 600\n",
    "    # set space between request, topology and spectrum parts of the game\n",
    "    MARGIN = 10\n",
    "    # set width of request space\n",
    "    INCOMINGREQUESTWIDTH = 200\n",
    "    # set width of topology space\n",
    "    NETWORKTOPOLOGYWIDTH = 560\n",
    "    # set width of spectrum space\n",
    "    SELECTEDLINKWIDTH = 200\n",
    "    # set space for score and timer at the top of the game screen\n",
    "    HEADER = 50\n",
    "    # set height of individual requests\n",
    "    REQUESTHEIGHT = 40\n",
    "    # set height of timer bar for individual requests\n",
    "    TIMERBARHEIGHT = 15\n",
    "    NUMBEROFSLOTS = 5\n",
    "    SPECTRUMBOXHEIGHT = 30\n",
    "    SPECTRUMBOXWIDTH = 120\n",
    "\n",
    "    # test if width of game spaces and margin fully cover the game screen width\n",
    "    assert WINDOWWIDTH == INCOMINGREQUESTWIDTH + NETWORKTOPOLOGYWIDTH + SELECTEDLINKWIDTH + 4*MARGIN\n",
    "    # set number of frame resets per second\n",
    "    FPS = 30\n",
    "\n",
    "    # define colours (RED, GREEN, BLUE)\n",
    "    RED = (255, 0, 0)\n",
    "    GRAY = (100, 100, 100)\n",
    "    WHITE = (255, 255, 255)\n",
    "    BLUE = (0, 0, 255)\n",
    "    BLACK = (0, 0, 0)\n",
    "    ORANGE = (255, 128, 0)\n",
    "    LIGHTGRAY = (150, 150, 150)\n",
    "    GREEN = (0, 255, 0)\n",
    "    # idk what this is\n",
    "    BGCOLOR = GRAY\n",
    "    # defined variable for colouring selected and unselected requests\n",
    "    colorRequest = BLACK\n",
    "\n",
    "    def __init__(self, nodeList, linkList, requestList, user):\n",
    "        \n",
    "        self.nodeList = nodeList\n",
    "        self.linkList = linkList\n",
    "        self.requestList = requestList\n",
    "        self.user = user\n",
    "\n",
    "        #ADDED also the req_num as the number of connection requests in the episode\n",
    "        self.req_num = len(requestList)\n",
    "        #debug\n",
    "        print(self.req_num)\n",
    "\n",
    "        #see if this changes things, setting action space to 6 actions only instead of 7 (original)\n",
    "        #changed to 4\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        self.initialise_values()\n",
    "        \n",
    "        \n",
    "\n",
    "    def initialise_values(self):\n",
    "        '''\n",
    "        Intial values when starting the game. This includes initializing Pygame, setting timer, initializing game display screen and requests.\n",
    "        This is used when initalizing and resetting the game.\n",
    "        '''\n",
    "        self.requestMode = True\n",
    "        self.topologyMode = False\n",
    "        self.spectrumMode = False\n",
    "        self.completions = []\n",
    "\n",
    "        # initialize pygame\n",
    "        pygame.init()\n",
    "\n",
    "        # timer\n",
    "        self.timer_event = pygame.USEREVENT+1\n",
    "        # repeatedly create an event on the event queue every 1000ms / 1s\n",
    "        pygame.time.set_timer(self.timer_event, 1000)\n",
    "        self.timer = 60\n",
    "        # timer for request timer bar\n",
    "        self.timer2 = 60\n",
    "        \n",
    "        # create an object to help track time\n",
    "        self.FPSCLOCK = pygame.time.Clock()\n",
    "        # Initialize a window or screen for display\n",
    "        self.DISPLAYSURF = pygame.display.set_mode((self.WINDOWWIDTH, self.WINDOWHEIGHT))\n",
    "        # Set the game window caption\n",
    "        pygame.display.set_caption('Demo Game')\n",
    "        # fill the game screen with gray\n",
    "        self.DISPLAYSURF.fill(self.BLACK)\n",
    "        # initialize score\n",
    "        self.SCORE = 0\n",
    "        self.reward = 0\n",
    "        \n",
    "        #ADDED cumulative reward\n",
    "        self.reward_sum = 0\n",
    "\n",
    "        #ADDED connection service flag (tracks the number of connections fulfilled)\n",
    "        self.req_complete = 0\n",
    "        \n",
    "        \n",
    "        # stores the requests available to the user in a list\n",
    "        self.activeRequests = []\n",
    "        # automatically selects the first request in the list when game starts\n",
    "        # self.user.selectRequest(self.requestList[0])\n",
    "        # setting value to end episode\n",
    "        self.done = False\n",
    "\n",
    "        # creating observation space for gym\n",
    "        self.observation_space = spaces.Box(\n",
    "            low= 0,\n",
    "            high = 255,\n",
    "            shape= (self.WINDOWWIDTH, self.WINDOWHEIGHT, 3),\n",
    "            dtype=np.uint8\n",
    "            )\n",
    "\n",
    "        self.info = {}\n",
    "\n",
    "        if self.user.getCurrentRequest() != None:\n",
    "            self.user.deselectRequest()\n",
    "\n",
    "        highlighted = [0]*self.NUMBEROFSLOTS\n",
    "        for node in self.nodeList:\n",
    "            node.setHighlighted(False)\n",
    "            node.setSelected(False)\n",
    "        for link in self.linkList:\n",
    "            link.setHighlighted(False)\n",
    "            link.setSelected(False)\n",
    "            link.setSpectrumHighlighted(highlighted)\n",
    "            link.setSpectrum(highlighted)\n",
    "        \n",
    "        self.completions = []\n",
    "\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        '''\n",
    "        Resets the game to start state\n",
    "        '''\n",
    "        self.initialise_values()\n",
    "        obs = np.array(pygame.surfarray.array3d(self.DISPLAYSURF), dtype=np.uint8)\n",
    "        print(obs.shape)\n",
    "        return obs\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        #debug print\n",
    "        #print(\"ACTION\")\n",
    "        #print(action)\n",
    "        \n",
    "\n",
    "        #TESTING THIS \n",
    "        #resetting the self.reward variable to be 0, thus for every step, the reward \n",
    "        #isnt the cumulative reward, rather the reward gained for the action state.\n",
    "        self.reward = 0\n",
    "        #cause the if action !=6 part sends the chosen agent action to return the reward\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "            # If game screen is closed, Pygame is stopped\n",
    "            if event.type == pygame.QUIT:\n",
    "                self.endGame()\n",
    "        # Updates requests and reduces timer every second\n",
    "            elif event.type == self.timer_event:\n",
    "                self.requestUpdate()\n",
    "\n",
    "            #editing this so only 4 actions\n",
    "            elif event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_UP:\n",
    "                    action =  0\n",
    "                elif event.key == pygame.K_DOWN:\n",
    "                    action = 1\n",
    "                #elif event.key == pygame.K_LEFT:\n",
    "                   #action = 2\n",
    "                #elif event.key == pygame.K_RIGHT:\n",
    "                    #action = 3\n",
    "                elif event.key == pygame.K_RETURN:\n",
    "                    #action = 4\n",
    "                    action = 2\n",
    "                elif event.key == pygame.K_BACKSPACE:\n",
    "                    #action = 5\n",
    "                    action = 3\n",
    "        #if action != 4:\n",
    "        if self.requestMode == True:\n",
    "            self.request_logic(action)\n",
    "        elif self.topologyMode == True:\n",
    "            self.topology_logic(action)\n",
    "        elif self.spectrumMode == True:\n",
    "            self.spectrum_logic(action)\n",
    "        \n",
    "        obs = np.array(pygame.surfarray.array3d(self.DISPLAYSURF), dtype=np.uint8)\n",
    "\n",
    "        # if (self.timer < self.requestList[-1].getTimeStart() and self.activeRequests == []) or self.timer == 0:\n",
    "        if self.timer == 0:\n",
    "            self.done = True\n",
    "            #debug print\n",
    "            print(\"Cumulative Reward Obtained (GAME END):\")\n",
    "            print(self.reward_sum)\n",
    "\n",
    "        self.info[self.timer2] = {\n",
    "            'display': obs,\n",
    "            'user': self.user\n",
    "            }\n",
    "\n",
    "        #debug THIS WORKS\n",
    "        #print(\"STEP REWARD:\")\n",
    "        #print(self.reward)\n",
    "        #adds the reward to the cumulative reward variable\n",
    "        self.reward_sum += self.reward\n",
    "\n",
    "        #updates the score based on the cumulative reward\n",
    "        #self.SCORE += self.reward\n",
    "\n",
    "        return obs, self.reward, self.done, self.info\n",
    "    \n",
    "    # def get_action(self):\n",
    "        \n",
    "        #  for event in pygame.event.get():\n",
    "        #     # If game screen is closed, Pygame is stopped\n",
    "        #     if event.type == pygame.QUIT:\n",
    "        #         self.endGame()\n",
    "        # # Updates requests and reduces timer every second\n",
    "        #     elif event.type == self.timer_event:\n",
    "        #         self.requestUpdate()\n",
    "\n",
    "        #     elif event.type == pygame.KEYDOWN:\n",
    "        #         if event.key == pygame.K_UP:\n",
    "        #             return 0\n",
    "        #         elif event.key == pygame.K_DOWN:\n",
    "        #             return 1\n",
    "        #         elif event.key == pygame.K_LEFT:\n",
    "        #             return 2\n",
    "        #         elif event.key == pygame.K_RIGHT:\n",
    "        #             return 3\n",
    "        #         elif event.key == pygame.K_RETURN:\n",
    "        #             return 4\n",
    "        #         elif event.key == pygame.K_BACKSPACE:\n",
    "        #             return 5\n",
    "        #         else:\n",
    "        #             return 6\n",
    "\n",
    "\n",
    "    def render(self, mode = \"human\"):\n",
    "        '''\n",
    "        Renders the game display screen and updates it per FPS value set. Includes drawing topolgy, requests, spectrum, score and timer.\n",
    "        '''\n",
    "        # for event in pygame.event.get():\n",
    "        #     # If game screen is closed, Pygame is stopped\n",
    "        #     if event.type == pygame.QUIT:\n",
    "        #         self.endGame()\n",
    "        \n",
    "            \n",
    "        # creating game screen\n",
    "        # fill the game screen with gray\n",
    "        self.DISPLAYSURF.fill(GRAY)\n",
    "        # display the score on the game scren\n",
    "        self.displayScore()\n",
    "        # display the timer on the game scren\n",
    "        self.displayTimer()\n",
    "\n",
    "        # draw topology on the game screen\n",
    "        self.drawTopologyScreen()\n",
    "        # draw requests on the game screen\n",
    "        self.drawRequestsScreen()\n",
    "        # draw spectrums on the game screen\n",
    "        self.drawSpectrumScreen()\n",
    "\n",
    "        # Update portions of the screen for software displays (in this case the entire screen is updated)      \n",
    "        pygame.display.update()\n",
    "\n",
    "        # timer2 decreases per frame to allow smooth decrease of timer bar width\n",
    "        self.timer2 -= 1/self.FPS\n",
    "        \n",
    "        # updates the clock once per frame\n",
    "        self.FPSCLOCK.tick(self.FPS)\n",
    "\n",
    "\n",
    "\n",
    "    def displayScore(self):\n",
    "        '''\n",
    "        Function to draw score on game screen.\n",
    "        Used in render().\n",
    "        '''\n",
    "        pygame.font.init()\n",
    "        myfont = pygame.font.SysFont('Calibri', 30)\n",
    "        textsurface = myfont.render(f'SCORE: {str(self.SCORE)}', False, WHITE)\n",
    "        self.DISPLAYSURF.blit(textsurface, (self.WINDOWWIDTH/2-70, 15))\n",
    "\n",
    "\n",
    "\n",
    "    def drawTopologyScreen(self):\n",
    "        '''\n",
    "        Function to draw topolgy on game screen.\n",
    "        Used in render().\n",
    "        '''\n",
    "        # highlighting the topology space when selecting path for easier recognition\n",
    "        if self.topologyMode == True:\n",
    "            color = self.RED\n",
    "        else:\n",
    "            color = self.BLACK\n",
    "\n",
    "        # Draw rectangle where topology is displayed in\n",
    "        pygame.draw.rect(self.DISPLAYSURF, color, (self.MARGIN + self.INCOMINGREQUESTWIDTH + self.MARGIN, \\\n",
    "            self.HEADER, self.NETWORKTOPOLOGYWIDTH, self.WINDOWHEIGHT - self.HEADER - self.MARGIN), 4)\n",
    "\n",
    "        for link in self.linkList:\n",
    "            link.drawLink(self.DISPLAYSURF, self.BLUE)\n",
    "            link.drawSpectrum(self.DISPLAYSURF, link.getX() - self.SPECTRUMBOXWIDTH/2, link.getY() - self.SPECTRUMBOXHEIGHT/2)\n",
    "\n",
    "        for node in self.nodeList:\n",
    "            node.drawNode(self.DISPLAYSURF, self.BLUE)\n",
    "        \n",
    "        \n",
    "\n",
    "    def drawRequestsScreen(self):\n",
    "        '''\n",
    "        Function to display requests on game screen.\n",
    "        Used in render().\n",
    "        '''\n",
    "        # highlighting the request space when selecting requests for easier recognition\n",
    "        if self.requestMode == True:\n",
    "            color = self.RED\n",
    "        else:\n",
    "            color = self.BLACK\n",
    "        \n",
    "        # Draw rectangle where requests are displayed in\n",
    "        pygame.draw.rect(self.DISPLAYSURF, color, (self.MARGIN, self.HEADER, self.INCOMINGREQUESTWIDTH, \\\n",
    "            self.WINDOWHEIGHT - self.HEADER - self.MARGIN), 4)\n",
    "        \n",
    "        # FOR each active request, draw a rectangle displaying the request within it\n",
    "        for i, request in enumerate(self.activeRequests):\n",
    "            requestBox = pygame.Rect(self.MARGIN, self.HEADER + i*(self.REQUESTHEIGHT + self.TIMERBARHEIGHT), self.INCOMINGREQUESTWIDTH, self.REQUESTHEIGHT)\n",
    "            # calculate the time left before request expires\n",
    "            timeLeft = request.timeLimit - (request.timeStart - self.timer2)\n",
    "            # draws a rectangle that indicates the time left for the request before it expires by decreasing its length\n",
    "            if timeLeft > 0:\n",
    "                pygame.draw.rect(self.DISPLAYSURF, self.ORANGE, (self.MARGIN, self.HEADER + (i+1)*self.REQUESTHEIGHT + i*self.TIMERBARHEIGHT, \\\n",
    "                    self.INCOMINGREQUESTWIDTH*timeLeft/request.timeLimit, self.TIMERBARHEIGHT))\n",
    "            # highlighting the selected request for easier recognition\n",
    "            if request.getSelected() == True:\n",
    "                colorRequest = self.RED\n",
    "            else:\n",
    "                colorRequest = self.LIGHTGRAY\n",
    "            pygame.draw.rect(self.DISPLAYSURF, colorRequest, requestBox)\n",
    "            pygame.font.init()\n",
    "            # display source and destination node, as well as bandwidth needed for each request\n",
    "            myfont = pygame.font.SysFont('Calibri', 30)\n",
    "            textsurface = myfont.render(f'({request.sourceNode.getName()}, {request.destNode.getName()}, {request.bandWidth})', False, WHITE)\n",
    "            text_rect = textsurface.get_rect(center=requestBox.center)\n",
    "            self.DISPLAYSURF.blit(textsurface, text_rect)\n",
    "\n",
    "\n",
    "\n",
    "    def drawSpectrumScreen(self):\n",
    "        '''\n",
    "        Function to draw links' spectrums on game screen. The spectrums are updated when they are allocated, and also when links are selected.\n",
    "        Used in render().\n",
    "        '''\n",
    "        # highlighting the spectrum space when doing spectrum allocation for easier recognition\n",
    "        if self.spectrumMode == True:\n",
    "            color = self.RED\n",
    "        else:\n",
    "            color = self.BLACK\n",
    "        \n",
    "        # Draw rectangle where spectrums are displayed in\n",
    "        spectrumBox = pygame.Rect((self.MARGIN + self.INCOMINGREQUESTWIDTH + self.MARGIN + self.NETWORKTOPOLOGYWIDTH + self.MARGIN, \\\n",
    "            self.HEADER, self.SELECTEDLINKWIDTH, self.WINDOWHEIGHT - self.HEADER - self.MARGIN))\n",
    "        pygame.draw.rect(self.DISPLAYSURF, color, spectrumBox, 4)\n",
    "\n",
    "        # drawing spectrum selected and unselected links\n",
    "        selectedLinks = []\n",
    "        for entry in self.user.getLinksSelected():\n",
    "            selectedLinks.append(entry[1])\n",
    "        unselectedLinks = self.linkList.copy()\n",
    "        for link in self.linkList:\n",
    "            if link in selectedLinks:\n",
    "                unselectedLinks.remove(link)\n",
    "        \n",
    "        # selected links text to display\n",
    "        pygame.font.init()\n",
    "        myfont = pygame.font.SysFont('Calibri', 27)\n",
    "        textsurface = myfont.render(f'Selected Links:', False, self.WHITE)\n",
    "        text_rect = textsurface.get_rect(center=spectrumBox.center)\n",
    "        self.DISPLAYSURF.blit(textsurface, (text_rect[0], self.HEADER + self.MARGIN))\n",
    "        \n",
    "        # drawing selected links\n",
    "        if selectedLinks != []:\n",
    "            for i in range(len(selectedLinks)):\n",
    "                textsurface = myfont.render(f'{selectedLinks[i].getName()}', False, self.WHITE)\n",
    "                self.DISPLAYSURF.blit(textsurface, (self.MARGIN + self.INCOMINGREQUESTWIDTH + self.MARGIN + self.NETWORKTOPOLOGYWIDTH + self.MARGIN + 6, \\\n",
    "                    self.HEADER + self.MARGIN + (i + 1)*(self.SPECTRUMBOXHEIGHT + 5)))\n",
    "                selectedLinks[i].drawSpectrum(self.DISPLAYSURF, self.MARGIN + self.INCOMINGREQUESTWIDTH + self.MARGIN + self.NETWORKTOPOLOGYWIDTH + \\\n",
    "                    self.MARGIN + 6 + 35, self.HEADER + self.MARGIN + (i + 1)*(self.SPECTRUMBOXHEIGHT + 5))\n",
    "\n",
    "        # unselected links text to display\n",
    "        textsurface = myfont.render(f'Unselected Links:', False, self.WHITE)\n",
    "        text_rect = textsurface.get_rect(center=spectrumBox.center)\n",
    "        self.DISPLAYSURF.blit(textsurface, (text_rect[0], self.HEADER + self.MARGIN + (len(selectedLinks) + 1)*(self.SPECTRUMBOXHEIGHT + 5)))\n",
    "\n",
    "        # drawing unselected links\n",
    "        if unselectedLinks != []:\n",
    "            for i in range(len(unselectedLinks)):\n",
    "                textsurface = myfont.render(f'{unselectedLinks[i].getName()}', False, self.WHITE)\n",
    "                self.DISPLAYSURF.blit(textsurface, (self.MARGIN + self.INCOMINGREQUESTWIDTH + self.MARGIN + self.NETWORKTOPOLOGYWIDTH + self.MARGIN + 6, \\\n",
    "                    self.HEADER + self.MARGIN + (len(selectedLinks) + 1)*(self.SPECTRUMBOXHEIGHT + 5) + (i + 1)*(self.SPECTRUMBOXHEIGHT + 5)))\n",
    "                unselectedLinks[i].drawSpectrum(self.DISPLAYSURF, self.MARGIN + self.INCOMINGREQUESTWIDTH + self.MARGIN + self.NETWORKTOPOLOGYWIDTH + \\\n",
    "                    self.MARGIN + 6 + 35, self.HEADER + self.MARGIN + (len(selectedLinks) + 1)*(self.SPECTRUMBOXHEIGHT + 5) + \\\n",
    "                    (i + 1)*(self.SPECTRUMBOXHEIGHT + 5))\n",
    "\n",
    "\n",
    "\n",
    "    # drawing clock\n",
    "    def displayTimer(self):\n",
    "        '''\n",
    "        Function to draw timer on game screen.\n",
    "        Used in render().\n",
    "        '''\n",
    "        pygame.font.init()\n",
    "        myfont = pygame.font.SysFont('Calibri', 30)\n",
    "        textsurface = myfont.render(f'Time: {str(self.timer)}', False, self.WHITE)\n",
    "        self.DISPLAYSURF.blit(textsurface, (self.WINDOWWIDTH - 150, 15))\n",
    "\n",
    "\n",
    "    def requestUpdate(self):\n",
    "        '''\n",
    "        Function to update the requests available to player. Adds and removes active requests.\n",
    "        Also updates the timer, decreasing it by one.\n",
    "        Used in render().\n",
    "        '''\n",
    "        # sending in requests\n",
    "        # occurs every secon\n",
    "        # FOR each request in the game\n",
    "        for request in self.requestList:\n",
    "            # IF the game timer matches the start time of the request\n",
    "            # THEN the request becomes active\n",
    "            if self.timer == request.timeStart:\n",
    "                self.activeRequests.append(request)\n",
    "        \n",
    "        for request in self.activeRequests:\n",
    "            # IF the game timer matches the end time of the request (calculated based on time limit of request)\n",
    "            # THEN the request is considered blocked and score decreases. Request is also de-activated\n",
    "            if self.timer == request.timeStart - request.timeLimit + 1:\n",
    "                request.setBlock(True)\n",
    "\n",
    "                #COMMENTED OUT, TESTING SCORE PRINTOUT\n",
    "                self.SCORE -= 1\n",
    "\n",
    "                #changed to -1\n",
    "                #reward expiry\n",
    "                #self.reward -= 100\n",
    "                self.reward -= 10\n",
    "                \n",
    "                #adding to the req_complete flag \n",
    "                self.req_complete += 1\n",
    "\n",
    "                if self.req_complete == self.req_num:\n",
    "\n",
    "                    #if the only connection expires then the episode ends\n",
    "                    #debug\n",
    "                    #changed this so that if the connection which expires is the final conn then the episode ends\n",
    "                    print(\"Request Timed Out, cumulative Reward:\")\n",
    "                    print(self.reward_sum)\n",
    "                    self.done = True\n",
    "\n",
    "                try:\n",
    "                    self.activeRequests.remove(request)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        # sets slots to 0 when the request runs out after allocation\n",
    "        for curr_request, link_list, spectrum in self.completions:\n",
    "            if self.timer == curr_request.getTimeDeallocated():\n",
    "                for link in link_list:\n",
    "                    spectrumCopy = link[1].getSpectrum().copy()\n",
    "                    for i, slot in enumerate(spectrum):\n",
    "                        if slot == 1:\n",
    "                            spectrumCopy[i] = 0\n",
    "\n",
    "                    link[1].setSpectrum(spectrumCopy)\n",
    "\n",
    "        # IF user has selected a request\n",
    "        if self.user.getCurrentRequest() != None:\n",
    "            # IF selected request expires before it is completed\n",
    "            # THEN the links selected by the user thus far is removed and the links the user can choose is reset\n",
    "            if self.timer == self.user.getCurrentRequest().timeStart - self.user.getCurrentRequest().timeLimit + 1 and self.requestMode == False:\n",
    "                availableLinks = self.clearAll()\n",
    "                \n",
    "\n",
    "            # ELSE when user has selected a request that has not expired, user can still continue to service it\n",
    "        # timer countsdown every second\n",
    "            elif self.timer == self.user.getCurrentRequest().timeStart - self.user.getCurrentRequest().timeLimit + 1 and self.requestMode == True:\n",
    "                self.user.deselectRequest()\n",
    "        # decrease timer by 1\n",
    "        self.timer -= 1\n",
    "        self.timer2 = self.timer\n",
    "        if self.user.getCurrentRequest() == None:\n",
    "            if self.activeRequests != []:\n",
    "                self.user.selectRequest(self.activeRequests[0])\n",
    "            \n",
    "\n",
    "    def request_logic(self, action):\n",
    "        # IF there are no selected requests and there are active requests\n",
    "        # THEN the first indexed request in the list of active requests is selected\n",
    "        # IN THE EVENT THAT selected request expires\n",
    "        # if self.user.getCurrentRequest() == None and self.activeRequests != []:\n",
    "        #     self.user.selectRequest(self.activeRequests[0])\n",
    "            \n",
    "        # IF there are not active requests\n",
    "        # THEN do nothing\n",
    "        if self.activeRequests == []:\n",
    "            \n",
    "            #placeholder reward to test \n",
    "            #changed to 2 from 4\n",
    "            if action == 2:\n",
    "                #print(\"no request (enter) reward\")\n",
    "                #originally set to + 10\n",
    "                #self.reward += 30\n",
    "                \n",
    "                #testing this normalised\n",
    "                #self.reward += 0.3\n",
    "                self.reward += 0.1\n",
    "\n",
    "            elif action == 0 or action == 1 or action == 3: \n",
    "                #originally set to -10\n",
    "                #self.reward -= 1\n",
    "\n",
    "                #testing this normalised\n",
    "                #self.reward -= 1\n",
    "                self.reward -= 1\n",
    "\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            # define number of active requests\n",
    "            activeRequestsLength = len(self.activeRequests)\n",
    "            # define the request the user is currently at\n",
    "            if self.user.getCurrentRequest() in self.activeRequests:\n",
    "                requestIndex = self.activeRequests.index(self.user.getCurrentRequest())\n",
    "            else:\n",
    "                return\n",
    "            # IF DOWN arrow key is pressed\n",
    "            # THEN the request below the current one is selected\n",
    "            if action == 1:\n",
    "                # IF DOWN arrow key is pressed and it is already the last request in the list\n",
    "                # THEN the first request in the list is selected\n",
    "                if requestIndex == activeRequestsLength - 1:\n",
    "                    requestIndex = 0\n",
    "                else:\n",
    "                    requestIndex += 1\n",
    "                # deselects the old request and selects the new one\n",
    "                self.user.deselectRequest()\n",
    "                self.user.selectRequest(self.activeRequests[requestIndex])\n",
    "\n",
    "                #Experimenting reward function\n",
    "                #unchanged\n",
    "                #self.reward -= 1\n",
    "\n",
    "                #testing this normalised\n",
    "                self.reward -= 0.1\n",
    "\n",
    "            # IF UP arrow key is pressed\n",
    "            # THEN the request above the current one is selected\n",
    "            elif action == 0:\n",
    "                # IF UP arrow key is pressed and it is already the first request in the list\n",
    "                # THEN the last request in the list is selected\n",
    "                if requestIndex == 0:\n",
    "                    requestIndex = activeRequestsLength - 1\n",
    "                else:\n",
    "                    requestIndex -= 1\n",
    "                # deselects the old request and selects the new one\n",
    "                self.user.deselectRequest()\n",
    "                self.user.selectRequest(self.activeRequests[requestIndex])\n",
    "\n",
    "                #Experimenting reward function\n",
    "                #unchanged\n",
    "                #self.reward -= 1\n",
    "\n",
    "                #testing this normalised\n",
    "                self.reward -= 0.1\n",
    "            \n",
    "            # IF ENTER key is pressed\n",
    "            # THEN the user moves to the topology space to service the request selected\n",
    "            #changed from 4 to 2\n",
    "            elif action == 2:\n",
    "                #self.reward += 0\n",
    "                #experimenting reward function\n",
    "                #changed to +10 originally\n",
    "                #changed to 20 on latest run\n",
    "                #print(\"enter with request\")\n",
    "                #self.reward += 30\n",
    "\n",
    "                #testing this normalised\n",
    "                self.reward += 1\n",
    "                \n",
    "                self.requestMode = False\n",
    "                self.topologyMode = True\n",
    "\n",
    "                #adding score reward for progressing from game mode\n",
    "                self.SCORE += 1\n",
    "\n",
    "                #TESTING if agent gets reward = current cumulative reward in each mode (so basically reset to 0 or times 2 if -ve or +ve)\n",
    "                #might need to change this to just adding like 20 as a one step reward if the agent passes into a new stage\n",
    "                #self.reward += 100\n",
    "\n",
    "                # user automatically starts at the source node of the request\n",
    "                self.user.setCurrentNode(self.user.currentRequest.getSourceNode())\n",
    "                # source node is automatically set as selected\n",
    "                self.user.getCurrentNode().setSelected(True)\n",
    "                # the first link and adjacent node connected to the source node (in the list) will be automatically highlighted\n",
    "                self.user.getCurrentNode().getLinks()[0][0].setHighlighted(True)\n",
    "                self.user.getCurrentNode().getLinks()[0][1].setHighlighted(True)\n",
    "                # defines index for use in topology space\n",
    "                self.index = 0\n",
    "\n",
    "                \n",
    "            #changed to only backspace (action 3)\n",
    "            elif action == 3:\n",
    "                #if left right or backspace pressed\n",
    "                #experimenting reward function\n",
    "                #changed to -10\n",
    "                #self.reward -= 5\n",
    "                \n",
    "                #testing this normalised\n",
    "                self.reward -= 1\n",
    "            \n",
    "\n",
    "\n",
    "    def topology_logic(self, action):\n",
    "        # IF BACKSPACE key is pressed\n",
    "        #changed to 3 for backspace from 5\n",
    "        if action == 3:\n",
    "            # IF BACKSPACE key is pressed and the user is at the source node\n",
    "            # THEN the user moves back to selecting a request, highlights will be reset\n",
    "            if self.user.getCurrentNode() == self.user.getCurrentRequest().getSourceNode():\n",
    "                for node in self.nodeList:\n",
    "                    node.setHighlighted(False)\n",
    "                    node.setSelected(False)\n",
    "                for link in self.linkList:\n",
    "                    link.setHighlighted(False)\n",
    "                    link.setSelected(False)\n",
    "                self.requestMode = True\n",
    "                self.topologyMode = False\n",
    "\n",
    "                #returning to request mode action\n",
    "                #experimenting reward function\n",
    "                #changed to -10\n",
    "                #self.reward -= 1\n",
    "                #self.reward -= 10\n",
    "\n",
    "                #testing this normalised\n",
    "                self.reward -= 1\n",
    "                \n",
    "            # IF BACKSPACE key is pressed and the user is not at the source node\n",
    "            # THEN the user moves back to previous node\n",
    "            else:\n",
    "                # define previous node and link pair from selected links list\n",
    "                previous = self.user.getLinksSelected()[-1]\n",
    "                # deselects the current node user is at\n",
    "                self.user.getCurrentNode().setSelected(False)\n",
    "                # selects the pervious node user was at\n",
    "                self.user.setCurrentNode(previous[0])\n",
    "\n",
    "\n",
    "                #experimenting reward function\n",
    "                #undoing routing selection\n",
    "                #set to -1\n",
    "                #self.reward -= 1\n",
    "\n",
    "                #testing this normalised\n",
    "                self.reward -= 0.1\n",
    "\n",
    "\n",
    "                # deselects the link user chose to get to the current node\n",
    "                previous[1].setSelected(False)\n",
    "                # removes the node and link pair from the selected links list\n",
    "                self.user.getLinksSelected().remove(previous)\n",
    "                \n",
    "                # removing all highlights (makes it easier since only highlights will be where user is at)\n",
    "                for node in self.nodeList:\n",
    "                    node.setHighlighted(False)\n",
    "                for link in self.linkList:\n",
    "                    link.setHighlighted(False)\n",
    "                # refreshes the links user can choose\n",
    "                availableLinks = self.checkAvailable()\n",
    "                # the first link and adjacent node connected to the current node (in the list) will be automatically highlighted\n",
    "                if availableLinks != []:\n",
    "                    availableLinks[self.index][0].setHighlighted(True)\n",
    "                    availableLinks[self.index][1].setHighlighted(True)\n",
    "        \n",
    "        # ELSE IF any button except BACKSPACE is pressed\n",
    "        else:\n",
    "            # refreshes the links user can choose\n",
    "            availableLinks = self.checkAvailable()\n",
    "            \n",
    "            # the first link and adjacent node connected to the current node (in the list) will be automatically highlighted\n",
    "            if availableLinks != []:\n",
    "                availableLinks[self.index][0].setHighlighted(True)\n",
    "                availableLinks[self.index][1].setHighlighted(True)\n",
    "            else:\n",
    "                # self.DISPLAYSURF.fill(self.RED)\n",
    "                pass\n",
    "                \n",
    "\n",
    "        # IF UP arrow key is pressed\n",
    "        # THEN the link above the current one is selected\n",
    "        if action == 0:\n",
    "            # de-highlights the current link\n",
    "            availableLinks[self.index][0].setHighlighted(False)\n",
    "            availableLinks[self.index][1].setHighlighted(False)\n",
    "            # IF UP arrow key is pressed and it is already the highest link\n",
    "            # THEN the lowest link is selected\n",
    "            if self.index == 0:\n",
    "                self.index = len(availableLinks) - 1\n",
    "            else:\n",
    "                self.index -= 1\n",
    "            # highlights the current link\n",
    "            availableLinks[self.index][0].setHighlighted(True)\n",
    "            availableLinks[self.index][1].setHighlighted(True)\n",
    "\n",
    "            #Experimenting reward function\n",
    "            #unchanged\n",
    "            #self.reward -= 1\n",
    "\n",
    "            #testing this normalised\n",
    "            self.reward += 0.5\n",
    "\n",
    "        # IF DOWN arrow key is pressed\n",
    "        # THEN the link below the current one is selected\n",
    "        elif action == 1:\n",
    "            # de-highlights the current link\n",
    "            availableLinks[self.index][0].setHighlighted(False)\n",
    "            availableLinks[self.index][1].setHighlighted(False)\n",
    "            # IF DOWN arrow key is pressed and it is already the lowest link\n",
    "            # THEN the highest link is selected\n",
    "            if self.index == len(availableLinks) - 1:\n",
    "                self.index = 0\n",
    "            else:\n",
    "                self.index += 1\n",
    "            # highlights the current link\n",
    "            availableLinks[self.index][0].setHighlighted(True)\n",
    "            availableLinks[self.index][1].setHighlighted(True)\n",
    "\n",
    "            #Experimenting reward function\n",
    "            #unchanged\n",
    "            #self.reward -= 1\n",
    "\n",
    "            #testing this normalised\n",
    "            self.reward += 0.5\n",
    "\n",
    "        # IF ENTER key is pressed\n",
    "        # THEN the user selects the link and moves to the adjacent node\n",
    "        #changed to 2 from 4 for smaller action steps\n",
    "        elif action == 2:\n",
    "            \n",
    "            #experimenting reward function\n",
    "            #commented out for now\n",
    "            #self.reward += 1\n",
    "            \n",
    "            # IF ENTER key is pressed and user has not reached the destination node\n",
    "            if self.user.getCurrentNode() != self.user.getCurrentRequest().getDestNode():\n",
    "                # IF the selected link does not move the user to the destination node\n",
    "                # THEN the link and node is de-highlighted and set to selected,\n",
    "                # user moves to the adjacent node connected to the selected link\n",
    "                if availableLinks[self.index][0] != self.user.getCurrentRequest().getDestNode():\n",
    "                    availableLinks[self.index][0].setHighlighted(False)\n",
    "                    availableLinks[self.index][1].setHighlighted(False)\n",
    "                    availableLinks[self.index][0].setSelected(True)\n",
    "                    availableLinks[self.index][1].setSelected(True)\n",
    "                    # current node and link selected is added to the list\n",
    "                    self.user.addLink(self.user.getCurrentNode(), availableLinks[self.index][1])\n",
    "                    # new current node is set to adjacent node connected to the selected link\n",
    "                    self.user.setCurrentNode(availableLinks[self.index][0])\n",
    "                    # index is set back to default 0 (as it is a new node)\n",
    "                    self.index = 0\n",
    "                    # links the user can choose are refreshed\n",
    "                    availableLinks = self.checkAvailable()\n",
    "                    # the first link and adjacent node connected to the current node (in the list) will be automatically highlighted\n",
    "                    if availableLinks != []:\n",
    "                        availableLinks[self.index][0].setHighlighted(True)\n",
    "                        availableLinks[self.index][1].setHighlighted(True)\n",
    "                    else:\n",
    "                        # undo selection\n",
    "                        # define previous node and link pair from selected links list\n",
    "                        previous = self.user.getLinksSelected()[-1]\n",
    "                        # deselects the current node user is at\n",
    "                        self.user.getCurrentNode().setSelected(False)\n",
    "                        # selects the pervious node user was at\n",
    "                        self.user.setCurrentNode(previous[0])\n",
    "\n",
    "                        # deselects the link user chose to get to the current node\n",
    "                        previous[1].setSelected(False)\n",
    "                        # removes the node and link pair from the selected links list\n",
    "                        self.user.getLinksSelected().remove(previous)\n",
    "                        \n",
    "                        # removing all highlights (makes it easier since only highlights will be where user is at)\n",
    "                        for node in self.nodeList:\n",
    "                            node.setHighlighted(False)\n",
    "                        for link in self.linkList:\n",
    "                            link.setHighlighted(False)\n",
    "                        # refreshes the links user can choose\n",
    "                        availableLinks = self.checkAvailable()\n",
    "                        availableLinks[self.index][0].setHighlighted(True)\n",
    "                        availableLinks[self.index][1].setHighlighted(True)\n",
    "                        self.DISPLAYSURF.fill(self.RED)\n",
    "\n",
    "                    #routing to a non destination node\n",
    "                    #Experimenting reward function\n",
    "                    #changed to +1\n",
    "                    #self.reward -= 5\n",
    "                    #self.reward += 1\n",
    "\n",
    "                    #testing this normalised\n",
    "                    self.reward += 0.1\n",
    "\n",
    "                # ELSE IF the selected link moves the user to the destination node\n",
    "                # THEN the link and node is de-highlighted and set to selected,\n",
    "                # user moves to the spectrum space for spectrum allocation\n",
    "                else:\n",
    "                    availableLinks[self.index][0].setHighlighted(False)\n",
    "                    availableLinks[self.index][1].setHighlighted(False)\n",
    "                    availableLinks[self.index][0].setSelected(True)\n",
    "                    availableLinks[self.index][1].setSelected(True)\n",
    "                    # current node and link selected is added to the list\n",
    "                    self.user.addLink(self.user.getCurrentNode(), availableLinks[self.index][1])\n",
    "                    self.topologyMode = False\n",
    "                    self.spectrumMode = True\n",
    "\n",
    "                    # need to include selecting first few slots automatically\n",
    "                    bandwidth = self.user.getCurrentRequest().getBandwidth()\n",
    "                    linksSelected = [link[1] for link in self.user.getLinksSelected()]\n",
    "                    highlightedSpectrum = [0]*self.NUMBEROFSLOTS\n",
    "                    for i in range(bandwidth):\n",
    "                        highlightedSpectrum[i] = 1\n",
    "                    for link in linksSelected:\n",
    "                        link.setSpectrumHighlighted(highlightedSpectrum)\n",
    "                    self.spectrumIndex = 0\n",
    "                    \n",
    "                    #moving to spectrum mode\n",
    "                    #Experimenting reward function\n",
    "                    #added reward + 20\n",
    "                    #self.reward += 30\n",
    "\n",
    "                    #testing this normalised\n",
    "                    self.reward += 1\n",
    "\n",
    "                    #adding score reward for progressing from game mode\n",
    "                    self.SCORE += 2\n",
    "\n",
    "                    #TESTING if agent gets reward = current cumulative reward in each mode (so basically reset to 0 or times 2 if -ve or +ve)\n",
    "                    #might need to change this to just adding like 20 as a one step reward if the agent passes into a new stage\n",
    "                    #self.reward += 100\n",
    "        \n",
    "        #commented out as left and right not used anymore\n",
    "        #elif action == 2 or action == 3:\n",
    "            #Experimenting reward function\n",
    "            #if left or right used\n",
    "            #changed to -20\n",
    "            #self.reward -= 5\n",
    "            #self.reward -= 20\n",
    "\n",
    "            #testing this normalised\n",
    "            #self.reward -= 1\n",
    "\n",
    "\n",
    "    def spectrum_logic(self, action):\n",
    "        # if backspace is pressed go back to topology mode\n",
    "        # should go back to node before destination node\n",
    "        # selected links should be deselected\n",
    "        # automatically highlight links\n",
    "        # removes the links from user selected links\n",
    "        #changed to 3 from 5 for new backsapce action value\n",
    "        if action == 3:\n",
    "            self.topologyMode = True\n",
    "            self.spectrumMode = False\n",
    "\n",
    "            linksSelected = [link[1] for link in self.user.getLinksSelected()]\n",
    "            highlightedSpectrum = [0]*NUMBEROFSLOTS\n",
    "            for link in linksSelected:\n",
    "                link.setSpectrumHighlighted(highlightedSpectrum)\n",
    "\n",
    "            links_selected = self.user.getLinksSelected()\n",
    "            self.user.setCurrentNode(links_selected[-1][0])\n",
    "            links_selected[-1][1].setSelected(False)\n",
    "            self.user.getCurrentRequest().getDestNode().setSelected(False)\n",
    "            availableLinks = self.checkAvailable()\n",
    "            availableLinks[self.index][0].setHighlighted(True)\n",
    "            availableLinks[self.index][1].setHighlighted(True)\n",
    "            self.user.getLinksSelected().remove(links_selected[-1])\n",
    "\n",
    "            #returning to topology mode\n",
    "            #Experimenting reward function\n",
    "            #changed to -20\n",
    "            #self.reward -= 1\n",
    "            #self.reward -= 20\n",
    "\n",
    "            #testing this normalised\n",
    "            self.reward -= 1\n",
    "            \n",
    "\n",
    "        # if left is pressed then the selected should be shifted to the left by 1 unless at the most left where it will jump to right\n",
    "        #LEFT CHANGED TO UP action is now 0 from 2\n",
    "        elif action == 0:\n",
    "            bandwidth = self.user.getCurrentRequest().getBandwidth()\n",
    "            if self.spectrumIndex == 0:\n",
    "                self.spectrumIndex = self.NUMBEROFSLOTS - bandwidth\n",
    "            else:\n",
    "                self.spectrumIndex -= 1\n",
    "            highlightedSpectrum = [0]*5\n",
    "            linksSelected = [link[1] for link in self.user.getLinksSelected()]\n",
    "            for i in range(bandwidth):\n",
    "                highlightedSpectrum[i + self.spectrumIndex] = 1\n",
    "            for link in linksSelected:\n",
    "                link.setSpectrumHighlighted(highlightedSpectrum)\n",
    "\n",
    "            #Experimenting reward function\n",
    "            #unchanged\n",
    "            #self.reward -= 1\n",
    "\n",
    "            #testing this normalised\n",
    "            self.reward += 0.5\n",
    "\n",
    "\n",
    "        # if right is pressed then the selected should be shifted to the right by 1 unless at the most right where it will jump to left\n",
    "        #RIGHT CHANGED TO down action is now 1 from 2\n",
    "        elif action == 1:\n",
    "            bandwidth = self.user.getCurrentRequest().getBandwidth()\n",
    "            if self.spectrumIndex == self.NUMBEROFSLOTS - bandwidth:\n",
    "                self.spectrumIndex = 0\n",
    "            else:\n",
    "                self.spectrumIndex += 1\n",
    "            highlightedSpectrum = [0]*5\n",
    "            linksSelected = [link[1] for link in self.user.getLinksSelected()]\n",
    "            for i in range(bandwidth):\n",
    "                highlightedSpectrum[i + self.spectrumIndex] = 1\n",
    "            for link in linksSelected:\n",
    "                link.setSpectrumHighlighted(highlightedSpectrum)\n",
    "            \n",
    "            #Experimenting reward function\n",
    "            #unchanged\n",
    "            #self.reward -= 1\n",
    "\n",
    "            #testing this normalised\n",
    "            self.reward += 0.5\n",
    "\n",
    "        # if return is pressed, selected links should be checked for if they are valid and if they are they should be selected and links\n",
    "        # should be updated\n",
    "        # otherwise an error message should pop up\n",
    "        #changed from 4 to 2 for enter\n",
    "        elif action == 2:\n",
    "            # check that there are no conflicts\n",
    "            linksSelected = [link[1] for link in self.user.getLinksSelected()]\n",
    "            possible = True\n",
    "            for link in linksSelected:\n",
    "                for i in range(self.NUMBEROFSLOTS):\n",
    "                    if link.getSpectrumHighlighted()[i] == 1:\n",
    "                        if link.getSpectrum()[i] == 1:\n",
    "                            # create error screen\n",
    "                            # self.DISPLAYSURF.fill(self.RED)\n",
    "                            # pygame.display.update()\n",
    "                            # print(\"error\")\n",
    "                            possible = False\n",
    "                            \n",
    "                            \n",
    "\n",
    "            if possible == True:\n",
    "                self.completions.append((self.user.getCurrentRequest(), self.user.getLinksSelected().copy(), link.getSpectrumHighlighted().copy()))\n",
    "                for link in linksSelected:\n",
    "                    newSelected = [sum(x) for x in zip(link.getSpectrum(), link.getSpectrumHighlighted())]\n",
    "                    link.setSpectrum(newSelected)\n",
    "                    highlightedSpectrum = [0]*5\n",
    "                    link.setSpectrumHighlighted(highlightedSpectrum)\n",
    "                # throw back into request mode and add point and deselect highlighted spectrum, remove request\n",
    "                \n",
    "                #COMMENTED OUT, TESTING SCORE PRINTOUT\n",
    "                self.SCORE += 5\n",
    "                \n",
    "                self.user.getCurrentRequest().complete()\n",
    "                self.activeRequests.remove(self.user.getCurrentRequest())\n",
    "                self.user.getCurrentRequest().setTimeAllocated(self.timer)\n",
    "                availableLinks = self.clearAll()\n",
    "\n",
    "                #successful spectrum assignment (one connection serviced)\n",
    "                #experimenting reward function\n",
    "                #changed to + 30\n",
    "                #self.reward += 100\n",
    "                #self.reward += 30\n",
    "\n",
    "                #testing this normalised\n",
    "                self.reward += 1\n",
    "                \n",
    "                #TESTING if agent gets reward = current cumulative reward in each mode (so basically reset to 0 or times 2 if -ve or +ve)\n",
    "                #might need to change this to just adding like 20 as a one step reward if the agent passes into a new stage\n",
    "                #self.reward += 100\n",
    "                \n",
    "\n",
    "                #adding to the req_complete flag \n",
    "                self.req_complete += 1\n",
    "\n",
    "                if self.req_complete == self.req_num:\n",
    "                    #changed so that if the number of requests is serviced then the episode ends\n",
    "                    #debug\n",
    "                    print(\"End episode, cumulative Reward:\")\n",
    "                    print(self.reward_sum)\n",
    "                    #CHANGE THIS SO THAT IT SUCCESSFULLY ENDS THE GAME UPON CONNECTION SERVICED\n",
    "                    self.done = True\n",
    "            \n",
    "            else:\n",
    "                #invalid spectrum assignment\n",
    "                #Experimenting reward function\n",
    "                #changed to - 10\n",
    "                #self.reward -= 5\n",
    "                #self.reward -= 30\n",
    "\n",
    "                #testing this normalised\n",
    "                self.reward -= 10\n",
    "\n",
    "        #commented out as they are not used now\n",
    "        #elif action == 0 or action == 1:\n",
    "            #if up or down are used (irrelevant controls in this mode)\n",
    "            #experimenting reward function \n",
    "            #changed to -20\n",
    "            #self.reward -= 5\n",
    "            #self.reward -= 20\n",
    "\n",
    "            #testing this normalised\n",
    "            #self.reward -= 1\n",
    "\n",
    "    def checkAvailable(self):\n",
    "        '''\n",
    "        Function to check whether links have been selected and removes from possible routes.\n",
    "        This means that the user will not be able to select links that have already been selected.\n",
    "        Used in clearAll()\n",
    "        '''\n",
    "        availableLinks = []\n",
    "        for entry in self.user.getCurrentNode().getLinks():\n",
    "            if (entry[1].getSelected() == False or entry[0].getSelected() == False) and entry[0].getSource() == False:\n",
    "                availableLinks.append(entry)\n",
    "                \n",
    "        return availableLinks\n",
    "    \n",
    "    \n",
    "    def clearAll(self):\n",
    "        '''\n",
    "        Clears all previously selected nodes and links.\n",
    "        Used in requestUpdate()\n",
    "        '''\n",
    "        self.user.getLinksSelected().clear()\n",
    "        availableLinks = self.checkAvailable()\n",
    "        # IF user has selected a request and is still trying to service the request when the request expired\n",
    "        # THEN the request is deselected, progress in servicing it will be reset, \n",
    "        # user then needs to choose another request\n",
    "        \n",
    "        # the request is deselcted automatically since it has expired\n",
    "        self.user.deselectRequest()\n",
    "        # nodes and links that user has selected or is selecting will be removed\n",
    "        highlighted = [0]*self.NUMBEROFSLOTS\n",
    "        for node in self.nodeList:\n",
    "            node.setHighlighted(False)\n",
    "            node.setSelected(False)\n",
    "        for link in self.linkList:\n",
    "            link.setHighlighted(False)\n",
    "            link.setSelected(False)\n",
    "            link.setSpectrumHighlighted(highlighted)\n",
    "        # user is returned to request mode\n",
    "        self.requestMode = True\n",
    "        self.topologyMode = False\n",
    "        self.spectrumMode = False\n",
    "        return availableLinks\n",
    "\n",
    "\n",
    "    def endGame(self):\n",
    "        '''\n",
    "        Function to end the game by quitting Pygame and exiting system.\n",
    "        Used in render()\n",
    "        '''\n",
    "        pygame.quit()\n",
    "        sys.exit()\n",
    "\n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating fixed test topology\n",
    "def createTestTopology():\n",
    "    # testNodes\n",
    "    nodeA = Node(0, 'A', 300, 200)\n",
    "    nodeB = Node(1, 'B', 300, 400)\n",
    "    nodeC = Node(2, 'C', 650, 200)\n",
    "    nodeD = Node(3, 'D', 650, 400)\n",
    "    # testLinks\n",
    "    link1 = Link(0, nodeA, nodeB)\n",
    "    link2 = Link(1, nodeB, nodeC)\n",
    "    link3 = Link(2, nodeB, nodeD)\n",
    "    link4 = Link(3, nodeA, nodeC)\n",
    "    link5 = Link(4, nodeC, nodeD)\n",
    "\n",
    "    nodeList = [nodeA, nodeB, nodeC, nodeD]\n",
    "    linkList = [link1, link2, link3, link4, link5]\n",
    "\n",
    "    # save the links associated to each node in a list\n",
    "    for node in nodeList:\n",
    "        node.setLinks(linkList)\n",
    "    return nodeList, linkList\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(values, moving_avg_period):\n",
    "    plt.figure(2)\n",
    "    plt.clf()        \n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(values)\n",
    "    \n",
    "    moving_avg = get_moving_average(moving_avg_period, values)\n",
    "    plt.plot(moving_avg)    \n",
    "    plt.pause(0.001)\n",
    "    print(\"Episode\", len(values), \"\\n\", \\\n",
    "        moving_avg_period, \"episode moving avg:\", moving_avg[-1])\n",
    "    if is_ipython: display.clear_output(wait=True)\n",
    "\n",
    "#plots the 100 episode moving average\n",
    "def get_moving_average(period, values):\n",
    "    values = torch.tensor(values, dtype=torch.float)\n",
    "    if len(values) >= period:\n",
    "        moving_avg = values.unfold(dimension=0, size=period, step=1) \\\n",
    "            .mean(dim=1).flatten(start_dim=0)\n",
    "        moving_avg = torch.cat((torch.zeros(period-1), moving_avg))\n",
    "        return moving_avg.numpy()\n",
    "    else:\n",
    "        moving_avg = torch.zeros(len(values))\n",
    "        return moving_avg.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN FUNCTION\n",
    "def main():\n",
    "\n",
    "    nodeList, linkList = createTestTopology()\n",
    "\n",
    "    #changed to only have 1 request per episode\n",
    "    #from 6 originally\n",
    "    requestList = generateRequests(nodeList, 6)\n",
    "\n",
    "    user = User()\n",
    "    eveon = game_gym(nodeList, linkList, requestList, user)\n",
    "\n",
    "    check_env(eveon, warn=True)\n",
    "\n",
    "    #hyperparameters testing\n",
    "    lr = 0.001\n",
    "    gamma = 0.8\n",
    "    eps_start = 1\n",
    "    eps_end = 0.15\n",
    "    train_freq = (100, \"step\")\n",
    "    target_update_interval = 2000\n",
    "    policy_kwarg = {\n",
    "        'net_arch': [64,64] #MLP hidden layer size\n",
    "    }\n",
    "    #learning_starts = 500 #memory warmup(?)\n",
    "\n",
    "\n",
    "    #added additional hyperparameters to test the training\n",
    "    #model = DQN('MlpPolicy', eveon, learning_rate=lr, verbose=1, buffer_size=100, device=\"auto\", gamma=gamma, exploration_initial_eps=eps_start, exploration_final_eps=eps_end, exploration_fraction=1)\n",
    "    \n",
    "    #added new parameters to DQN model\n",
    "    model = DQN('MlpPolicy', eveon, batch_size=32 ,buffer_size=600, verbose=1, device=\"auto\", learning_rate=lr, gamma=gamma, exploration_fraction=0.7, exploration_initial_eps=eps_start, exploration_final_eps=eps_end, target_update_interval=target_update_interval, train_freq=train_freq)\n",
    "    #for the model might want to change to CnnPolicy (used when DQN uses images as input)\n",
    "\n",
    "    #added log for every 3000 timesteps\n",
    "    model.learn(total_timesteps=200000)\n",
    "    \n",
    "    '''\n",
    "    for i in range(6):\n",
    "        #for loop which increases the number of requests per training loop\n",
    "        req_num = random.randint(1, i + 2)\n",
    "\n",
    "        #generate requestlist for for loop\n",
    "        requestList = generateRequests(nodeList, req_num)\n",
    "\n",
    "        model.learn(total_timesteps=15000)\n",
    "        \n",
    "        #debug for training\n",
    "        print(\"Model Trained with \" + str(req_num) + \" requests\")\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    model.save(\"DQNEveon_testing\")\n",
    "\n",
    "    \n",
    "    # THIS IS THE TESTING LOOP OF THE AGENT PLAYING THE GAME\n",
    "    obs = eveon.reset()\n",
    "    while True :\n",
    "        action, states_ = model.predict(obs, deterministic=False)\n",
    "        # action = 6\n",
    "        obs, rewards, dones, info = eveon.step(action)\n",
    "        \n",
    "        print(\"Action:\")\n",
    "        print(action)\n",
    "        #time.sleep(1)\n",
    "        #clear_output(wait=True)\n",
    "\n",
    "\n",
    "        if dones == True:\n",
    "            #debug print\n",
    "            print(\"########################Reward Obtained:\")\n",
    "            print(eveon.reward)\n",
    "            # with open('info.json', 'w') as outfile:\n",
    "            #     json.dump(info, outfile)\n",
    "\n",
    "            eveon.reset()\n",
    "\n",
    "        eveon.render()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "(1000, 600, 3)\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "7.900000000000004\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-266.69999999999965\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-317.1000000000002\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-204.00000000000009\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 576      |\n",
      "|    ep_rew_mean      | -194     |\n",
      "|    exploration_rate | 0.986    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 2304     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-281.50000000000114\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-214.0999999999996\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-353.4000000000005\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-177.3999999999994\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 686      |\n",
      "|    ep_rew_mean      | -226     |\n",
      "|    exploration_rate | 0.967    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 5488     |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-488.9000000000017\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-292.5000000000013\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-254.89999999999992\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-419.7000000000003\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 748      |\n",
      "|    ep_rew_mean      | -272     |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 33       |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 8978     |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-350.2999999999996\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-457.3999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-258.60000000000014\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-252.59999999999954\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 767      |\n",
      "|    ep_rew_mean      | -286     |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 35       |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 12274    |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-340.6\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-525.5999999999998\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-310.5000000000015\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-279.89999999999986\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 781      |\n",
      "|    ep_rew_mean      | -301     |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 426      |\n",
      "|    total_timesteps  | 15618    |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-300.2000000000013\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-211.79999999999967\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-379.30000000000234\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-309.90000000000214\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 798      |\n",
      "|    ep_rew_mean      | -301     |\n",
      "|    exploration_rate | 0.884    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 514      |\n",
      "|    total_timesteps  | 19159    |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-427.0999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-266.8999999999997\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-326.6000000000012\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-398.1999999999998\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 812      |\n",
      "|    ep_rew_mean      | -309     |\n",
      "|    exploration_rate | 0.862    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 602      |\n",
      "|    total_timesteps  | 22746    |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-258.90000000000106\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-272.79999999999995\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-342.9000000000012\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-163.69999999999948\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 810      |\n",
      "|    ep_rew_mean      | -303     |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 37       |\n",
      "|    time_elapsed     | 684      |\n",
      "|    total_timesteps  | 25918    |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-392.5000000000006\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-370.9999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-196.09999999999954\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-290.7000000000006\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 814      |\n",
      "|    ep_rew_mean      | -304     |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 767      |\n",
      "|    total_timesteps  | 29295    |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-306.80000000000075\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-289.0000000000001\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-248.39999999999978\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-367.9000000000025\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 822      |\n",
      "|    ep_rew_mean      | -304     |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 861      |\n",
      "|    total_timesteps  | 32877    |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-317.4000000000017\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-361.19999999999953\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-174.6999999999996\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-348.90000000000043\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 821      |\n",
      "|    ep_rew_mean      | -304     |\n",
      "|    exploration_rate | 0.781    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 944      |\n",
      "|    total_timesteps  | 36110    |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-306.5000000000001\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-371.60000000000105\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-446.50000000000017\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-284.80000000000075\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 823      |\n",
      "|    ep_rew_mean      | -308     |\n",
      "|    exploration_rate | 0.76     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 1028     |\n",
      "|    total_timesteps  | 39512    |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-264.5999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-356.1000000000015\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-281.1999999999997\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-353.89999999999964\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 821      |\n",
      "|    ep_rew_mean      | -308     |\n",
      "|    exploration_rate | 0.741    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 1113     |\n",
      "|    total_timesteps  | 42698    |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-293.7000000000005\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-276.10000000000065\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-315.5000000000008\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-428.89999999999964\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 820      |\n",
      "|    ep_rew_mean      | -309     |\n",
      "|    exploration_rate | 0.721    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 1196     |\n",
      "|    total_timesteps  | 45902    |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-305.6999999999996\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-316.50000000000045\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-261.2000000000003\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-484.70000000000107\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 821      |\n",
      "|    ep_rew_mean      | -312     |\n",
      "|    exploration_rate | 0.701    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 38       |\n",
      "|    time_elapsed     | 1283     |\n",
      "|    total_timesteps  | 49261    |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-306.4999999999998\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-140.80000000000007\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-360.5999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-317.8\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 795      |\n",
      "|    ep_rew_mean      | -310     |\n",
      "|    exploration_rate | 0.691    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 1380     |\n",
      "|    total_timesteps  | 50883    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.561    |\n",
      "|    n_updates        | 8        |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-481.29999999999995\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-259.4\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-495.20000000000016\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-698.0\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 767      |\n",
      "|    ep_rew_mean      | -320     |\n",
      "|    exploration_rate | 0.683    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 34       |\n",
      "|    time_elapsed     | 1491     |\n",
      "|    total_timesteps  | 52189    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.96     |\n",
      "|    n_updates        | 21       |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-176.5999999999997\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-235.69999999999985\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-347.90000000000003\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-154.49999999999986\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 741      |\n",
      "|    ep_rew_mean      | -315     |\n",
      "|    exploration_rate | 0.676    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 32       |\n",
      "|    time_elapsed     | 1621     |\n",
      "|    total_timesteps  | 53364    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 15.6     |\n",
      "|    n_updates        | 33       |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-76.19999999999996\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-303.6\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-471.19999999999993\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-423.2\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 715      |\n",
      "|    ep_rew_mean      | -316     |\n",
      "|    exploration_rate | 0.67     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 31       |\n",
      "|    time_elapsed     | 1722     |\n",
      "|    total_timesteps  | 54305    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.93     |\n",
      "|    n_updates        | 43       |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-663.4\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-785.3999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-768.1\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-404.1\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 696      |\n",
      "|    ep_rew_mean      | -333     |\n",
      "|    exploration_rate | 0.662    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 30       |\n",
      "|    time_elapsed     | 1833     |\n",
      "|    total_timesteps  | 55652    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 2.27     |\n",
      "|    n_updates        | 56       |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-229.1999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-406.9000000000001\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "11.200000000000005\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-38.40000000000002\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 678      |\n",
      "|    ep_rew_mean      | -325     |\n",
      "|    exploration_rate | 0.654    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 29       |\n",
      "|    time_elapsed     | 1946     |\n",
      "|    total_timesteps  | 56951    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 6.81     |\n",
      "|    n_updates        | 69       |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-184.4000000000001\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "13.299999999999997\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-170.7\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-38.10000000000003\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 663      |\n",
      "|    ep_rew_mean      | -314     |\n",
      "|    exploration_rate | 0.646    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 2069     |\n",
      "|    total_timesteps  | 58317    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 4.29     |\n",
      "|    n_updates        | 83       |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-72.19999999999973\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "13.099999999999943\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-44.30000000000019\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-9.100000000000003\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 651      |\n",
      "|    ep_rew_mean      | -302     |\n",
      "|    exploration_rate | 0.637    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 2205     |\n",
      "|    total_timesteps  | 59861    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 4.62     |\n",
      "|    n_updates        | 98       |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "38.0999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-25.10000000000005\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "16.79999999999996\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-205.79999999999998\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 639      |\n",
      "|    ep_rew_mean      | -292     |\n",
      "|    exploration_rate | 0.628    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 26       |\n",
      "|    time_elapsed     | 2344     |\n",
      "|    total_timesteps  | 61348    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.876    |\n",
      "|    n_updates        | 113      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-20.90000000000012\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-19.600000000000065\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-20.700000000000074\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-6.40000000000007\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 627      |\n",
      "|    ep_rew_mean      | -281     |\n",
      "|    exploration_rate | 0.619    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 25       |\n",
      "|    time_elapsed     | 2466     |\n",
      "|    total_timesteps  | 62713    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 127      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-18.300000000000004\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "38.59999999999994\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-12.399999999999997\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-58.30000000000015\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 618      |\n",
      "|    ep_rew_mean      | -274     |\n",
      "|    exploration_rate | 0.611    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 24       |\n",
      "|    time_elapsed     | 2596     |\n",
      "|    total_timesteps  | 64116    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 4.12     |\n",
      "|    n_updates        | 141      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "8.900000000000038\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "18.100000000000005\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-274.6\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-712.0999999999999\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 600      |\n",
      "|    ep_rew_mean      | -274     |\n",
      "|    exploration_rate | 0.603    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 24       |\n",
      "|    time_elapsed     | 2715     |\n",
      "|    total_timesteps  | 65441    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 2.51     |\n",
      "|    n_updates        | 154      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-18.20000000000001\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "32.89999999999998\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-43.40000000000011\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-321.00000000000034\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 579      |\n",
      "|    ep_rew_mean      | -263     |\n",
      "|    exploration_rate | 0.594    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 23       |\n",
      "|    time_elapsed     | 2843     |\n",
      "|    total_timesteps  | 66845    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 8.12     |\n",
      "|    n_updates        | 168      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "55.59999999999996\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "9.700000000000006\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "0.6000000000000241\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "5.099999999999989\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 560      |\n",
      "|    ep_rew_mean      | -249     |\n",
      "|    exploration_rate | 0.586    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 2975     |\n",
      "|    total_timesteps  | 68233    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 2.09     |\n",
      "|    n_updates        | 182      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "20.300000000000026\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-45.49999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "11.199999999999983\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "1.1000000000000134\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 541      |\n",
      "|    ep_rew_mean      | -235     |\n",
      "|    exploration_rate | 0.577    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 3111     |\n",
      "|    total_timesteps  | 69718    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 197      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "29.799999999999947\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "32.10000000000001\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-11.400000000000043\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-0.19999999999999218\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 519      |\n",
      "|    ep_rew_mean      | -223     |\n",
      "|    exploration_rate | 0.568    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 21       |\n",
      "|    time_elapsed     | 3246     |\n",
      "|    total_timesteps  | 71101    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 4.72     |\n",
      "|    n_updates        | 211      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-10.59999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "15.199999999999955\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "24.000000000000007\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "9.100000000000017\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 497      |\n",
      "|    ep_rew_mean      | -209     |\n",
      "|    exploration_rate | 0.56     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 21       |\n",
      "|    time_elapsed     | 3372     |\n",
      "|    total_timesteps  | 72412    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.171    |\n",
      "|    n_updates        | 224      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-263.4\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-275.4\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-34.39999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-233.70000000000002\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 472      |\n",
      "|    ep_rew_mean      | -206     |\n",
      "|    exploration_rate | 0.556    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 21       |\n",
      "|    time_elapsed     | 3476     |\n",
      "|    total_timesteps  | 73110    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 7.15     |\n",
      "|    n_updates        | 231      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-171.5\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-384.4\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-516.0\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-217.19999999999962\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 447      |\n",
      "|    ep_rew_mean      | -207     |\n",
      "|    exploration_rate | 0.551    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 20       |\n",
      "|    time_elapsed     | 3576     |\n",
      "|    total_timesteps  | 73974    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.6      |\n",
      "|    n_updates        | 239      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-9.999999999999986\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "14.299999999999955\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-1.8999999999999875\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-15.299999999999983\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 422      |\n",
      "|    ep_rew_mean      | -195     |\n",
      "|    exploration_rate | 0.544    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 20       |\n",
      "|    time_elapsed     | 3712     |\n",
      "|    total_timesteps  | 75093    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.86     |\n",
      "|    n_updates        | 250      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-12.30000000000001\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "24.899999999999984\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "15.299999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "10.399999999999975\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 400      |\n",
      "|    ep_rew_mean      | -183     |\n",
      "|    exploration_rate | 0.538    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 19       |\n",
      "|    time_elapsed     | 3850     |\n",
      "|    total_timesteps  | 76137    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.433    |\n",
      "|    n_updates        | 261      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "9.5\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-53.5000000000001\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-29.900000000000084\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-0.29999999999999005\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 378      |\n",
      "|    ep_rew_mean      | -170     |\n",
      "|    exploration_rate | 0.531    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 19       |\n",
      "|    time_elapsed     | 3989     |\n",
      "|    total_timesteps  | 77274    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.109    |\n",
      "|    n_updates        | 272      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-48.00000000000001\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-333.6\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-671.5999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-578.0999999999999\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 356      |\n",
      "|    ep_rew_mean      | -174     |\n",
      "|    exploration_rate | 0.524    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 19       |\n",
      "|    time_elapsed     | 4118     |\n",
      "|    total_timesteps  | 78324    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 2.81     |\n",
      "|    n_updates        | 283      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-87.10000000000002\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-49.70000000000011\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-10.699999999999982\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-17.60000000000008\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 336      |\n",
      "|    ep_rew_mean      | -163     |\n",
      "|    exploration_rate | 0.518    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 4253     |\n",
      "|    total_timesteps  | 79463    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.388    |\n",
      "|    n_updates        | 294      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-374.0\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-393.5\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-464.79999999999984\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-277.90000000000003\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 309      |\n",
      "|    ep_rew_mean      | -164     |\n",
      "|    exploration_rate | 0.513    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 4364     |\n",
      "|    total_timesteps  | 80207    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.39     |\n",
      "|    n_updates        | 302      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-518.7999999999997\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-660.1999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-590.5999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "9.600000000000001\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 302      |\n",
      "|    ep_rew_mean      | -171     |\n",
      "|    exploration_rate | 0.508    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 4473     |\n",
      "|    total_timesteps  | 81082    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.86     |\n",
      "|    n_updates        | 310      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-32.099999999999994\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "13.899999999999986\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-34.40000000000001\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "37.69999999999994\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 298      |\n",
      "|    ep_rew_mean      | -152     |\n",
      "|    exploration_rate | 0.502    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 17       |\n",
      "|    time_elapsed     | 4611     |\n",
      "|    total_timesteps  | 82021    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.84     |\n",
      "|    n_updates        | 320      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-0.5999999999999873\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "7.299999999999988\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-23.19999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "29.39999999999997\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 295      |\n",
      "|    ep_rew_mean      | -142     |\n",
      "|    exploration_rate | 0.497    |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 17       |\n",
      "|    time_elapsed     | 4740     |\n",
      "|    total_timesteps  | 82887    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.089    |\n",
      "|    n_updates        | 328      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-12.699999999999996\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-11.999999999999986\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "50.19999999999996\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-4.10000000000001\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 295      |\n",
      "|    ep_rew_mean      | -130     |\n",
      "|    exploration_rate | 0.491    |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 17       |\n",
      "|    time_elapsed     | 4875     |\n",
      "|    total_timesteps  | 83771    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 2.27     |\n",
      "|    n_updates        | 337      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "1.8000000000000118\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "17.499999999999964\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-13.799999999999986\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-28.200000000000102\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 291      |\n",
      "|    ep_rew_mean      | -104     |\n",
      "|    exploration_rate | 0.485    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 16       |\n",
      "|    time_elapsed     | 5018     |\n",
      "|    total_timesteps  | 84784    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.619    |\n",
      "|    n_updates        | 347      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-207.5\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-462.29999999999984\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-381.8\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-228.30000000000004\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 286      |\n",
      "|    ep_rew_mean      | -110     |\n",
      "|    exploration_rate | 0.48     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 16       |\n",
      "|    time_elapsed     | 5131     |\n",
      "|    total_timesteps  | 85598    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.91     |\n",
      "|    n_updates        | 355      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-446.4999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-233.70000000000002\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-282.79999999999995\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-348.5\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 279      |\n",
      "|    ep_rew_mean      | -119     |\n",
      "|    exploration_rate | 0.476    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 16       |\n",
      "|    time_elapsed     | 5223     |\n",
      "|    total_timesteps  | 86266    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.997    |\n",
      "|    n_updates        | 362      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-366.79999999999995\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-688.1999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-583.3\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-12.199999999999974\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 272      |\n",
      "|    ep_rew_mean      | -134     |\n",
      "|    exploration_rate | 0.471    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 16       |\n",
      "|    time_elapsed     | 5333     |\n",
      "|    total_timesteps  | 87101    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 2.18     |\n",
      "|    n_updates        | 371      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-5.099999999999998\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "17.999999999999943\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "1.0000000000000098\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-15.099999999999982\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 268      |\n",
      "|    ep_rew_mean      | -133     |\n",
      "|    exploration_rate | 0.465    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 16       |\n",
      "|    time_elapsed     | 5471     |\n",
      "|    total_timesteps  | 88132    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.347    |\n",
      "|    n_updates        | 381      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-111.79999999999997\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-54.90000000000005\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-11.400000000000025\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-0.800000000000009\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 264      |\n",
      "|    ep_rew_mean      | -134     |\n",
      "|    exploration_rate | 0.459    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 5613     |\n",
      "|    total_timesteps  | 89131    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 8.25     |\n",
      "|    n_updates        | 391      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-3.2999999999999883\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-4.199999999999973\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-17.299999999999997\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "0.4999999999999838\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 261      |\n",
      "|    ep_rew_mean      | -134     |\n",
      "|    exploration_rate | 0.452    |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 5756     |\n",
      "|    total_timesteps  | 90201    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.524    |\n",
      "|    n_updates        | 402      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "19.79999999999992\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-5.399999999999983\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-3.999999999999986\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-8.199999999999998\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 257      |\n",
      "|    ep_rew_mean      | -125     |\n",
      "|    exploration_rate | 0.446    |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 5895     |\n",
      "|    total_timesteps  | 91182    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0861   |\n",
      "|    n_updates        | 411      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "4.099999999999987\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-24.400000000000006\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-35.70000000000002\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-78.1\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 253      |\n",
      "|    ep_rew_mean      | -123     |\n",
      "|    exploration_rate | 0.44     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 6033     |\n",
      "|    total_timesteps  | 92178    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.96     |\n",
      "|    n_updates        | 421      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "20.599999999999987\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-2.5999999999999943\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-10.600000000000012\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "6.399999999999967\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -123     |\n",
      "|    exploration_rate | 0.434    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 6171     |\n",
      "|    total_timesteps  | 93203    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.955    |\n",
      "|    n_updates        | 432      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-30.700000000000024\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-109.89999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-551.5999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-393.6000000000009\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 244      |\n",
      "|    ep_rew_mean      | -134     |\n",
      "|    exploration_rate | 0.429    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 6294     |\n",
      "|    total_timesteps  | 94120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 4.72     |\n",
      "|    n_updates        | 441      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-505.4999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-633.5\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-454.80000000000064\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-16.600000000000023\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 239      |\n",
      "|    ep_rew_mean      | -150     |\n",
      "|    exploration_rate | 0.423    |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 6396     |\n",
      "|    total_timesteps  | 94979    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 3.9      |\n",
      "|    n_updates        | 449      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-408.60000000000065\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-644.4999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-353.70000000000005\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-263.8000000000007\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 234      |\n",
      "|    ep_rew_mean      | -167     |\n",
      "|    exploration_rate | 0.418    |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 6505     |\n",
      "|    total_timesteps  | 95818    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 3.44     |\n",
      "|    n_updates        | 458      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-516.8999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-559.8999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-608.9999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-546.6999999999999\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 235      |\n",
      "|    ep_rew_mean      | -181     |\n",
      "|    exploration_rate | 0.413    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 6605     |\n",
      "|    total_timesteps  | 96601    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 4.13     |\n",
      "|    n_updates        | 466      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-427.1\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-584.3\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-568.2000000000007\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-9.500000000000039\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 236      |\n",
      "|    ep_rew_mean      | -184     |\n",
      "|    exploration_rate | 0.408    |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 6720     |\n",
      "|    total_timesteps  | 97551    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.999    |\n",
      "|    n_updates        | 475      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "0.5000000000000142\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-35.300000000000075\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "20.29999999999997\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-26.40000000000005\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 235      |\n",
      "|    ep_rew_mean      | -184     |\n",
      "|    exploration_rate | 0.402    |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 6857     |\n",
      "|    total_timesteps  | 98571    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.91     |\n",
      "|    n_updates        | 485      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-29.10000000000003\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "57.59999999999997\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "19.699999999999946\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-73.09999999999985\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 235      |\n",
      "|    ep_rew_mean      | -185     |\n",
      "|    exploration_rate | 0.395    |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 6997     |\n",
      "|    total_timesteps  | 99646    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.311    |\n",
      "|    n_updates        | 496      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "16.899999999999963\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-28.900000000000084\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "5.59999999999995\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "2.399999999999979\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 234      |\n",
      "|    ep_rew_mean      | -184     |\n",
      "|    exploration_rate | 0.389    |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 7131     |\n",
      "|    total_timesteps  | 100646   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0718   |\n",
      "|    n_updates        | 506      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "2.8000000000000065\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-6.299999999999976\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-10.099999999999982\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-39.20000000000002\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 233      |\n",
      "|    ep_rew_mean      | -169     |\n",
      "|    exploration_rate | 0.383    |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7274     |\n",
      "|    total_timesteps  | 101625   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 4.53     |\n",
      "|    n_updates        | 516      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "10.599999999999966\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-3.5999999999999837\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "10.499999999999964\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-2.7000000000000455\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 230      |\n",
      "|    ep_rew_mean      | -167     |\n",
      "|    exploration_rate | 0.378    |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7409     |\n",
      "|    total_timesteps  | 102445   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.099    |\n",
      "|    n_updates        | 524      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "42.899999999999956\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-406.7\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-937.5999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-680.1999999999998\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 232      |\n",
      "|    ep_rew_mean      | -172     |\n",
      "|    exploration_rate | 0.372    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7528     |\n",
      "|    total_timesteps  | 103382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 3.47     |\n",
      "|    n_updates        | 533      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-2.999999999999991\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-24.19999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-14.499999999999986\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-29.30000000000001\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 233      |\n",
      "|    ep_rew_mean      | -155     |\n",
      "|    exploration_rate | 0.366    |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7669     |\n",
      "|    total_timesteps  | 104406   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0725   |\n",
      "|    n_updates        | 544      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-41.10000000000005\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-43.10000000000001\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "3.599999999999955\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-15.900000000000047\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 235      |\n",
      "|    ep_rew_mean      | -156     |\n",
      "|    exploration_rate | 0.36     |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7809     |\n",
      "|    total_timesteps  | 105480   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.379    |\n",
      "|    n_updates        | 554      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-21.399999999999974\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-648.0999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-97.30000000000017\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-699.8\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 234      |\n",
      "|    ep_rew_mean      | -171     |\n",
      "|    exploration_rate | 0.355    |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 7909     |\n",
      "|    total_timesteps  | 106270   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.92     |\n",
      "|    n_updates        | 562      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-554.9\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-743.8999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-0.8000000000000069\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "25.299999999999926\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 234      |\n",
      "|    ep_rew_mean      | -184     |\n",
      "|    exploration_rate | 0.349    |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 8034     |\n",
      "|    total_timesteps  | 107169   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.94     |\n",
      "|    n_updates        | 571      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "3.600000000000009\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "2.399999999999955\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "2.9000000000000132\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-64.30000000000003\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 234      |\n",
      "|    ep_rew_mean      | -184     |\n",
      "|    exploration_rate | 0.343    |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 8177     |\n",
      "|    total_timesteps  | 108232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.039    |\n",
      "|    n_updates        | 582      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "48.79999999999997\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-9.300000000000008\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "6.600000000000032\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-5.6\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 236      |\n",
      "|    ep_rew_mean      | -171     |\n",
      "|    exploration_rate | 0.337    |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 8318     |\n",
      "|    total_timesteps  | 109220   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.412    |\n",
      "|    n_updates        | 592      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-5.1000000000000085\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "33.0\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-3.1999999999999993\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "3.49999999999996\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 239      |\n",
      "|    ep_rew_mean      | -158     |\n",
      "|    exploration_rate | 0.331    |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 8453     |\n",
      "|    total_timesteps  | 110191   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.369    |\n",
      "|    n_updates        | 601      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-24.30000000000004\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-5.000000000000023\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-673.8\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-533.0999999999999\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 241      |\n",
      "|    ep_rew_mean      | -154     |\n",
      "|    exploration_rate | 0.325    |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 8586     |\n",
      "|    total_timesteps  | 111153   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.88     |\n",
      "|    n_updates        | 611      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-857.4\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-636.6999999999998\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-463.59999999999997\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-583.0999999999999\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 238      |\n",
      "|    ep_rew_mean      | -179     |\n",
      "|    exploration_rate | 0.32     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 8699     |\n",
      "|    total_timesteps  | 111943   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 3.13     |\n",
      "|    n_updates        | 619      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "20.399999999999963\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "12.599999999999998\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "3.4000000000000146\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-0.5000000000000142\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 238      |\n",
      "|    ep_rew_mean      | -177     |\n",
      "|    exploration_rate | 0.314    |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 8837     |\n",
      "|    total_timesteps  | 112920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.652    |\n",
      "|    n_updates        | 629      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "16.599999999999987\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-2.4\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "3.6000000000000303\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "20.699999999999953\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 237      |\n",
      "|    ep_rew_mean      | -176     |\n",
      "|    exploration_rate | 0.308    |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 8972     |\n",
      "|    total_timesteps  | 113895   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0468   |\n",
      "|    n_updates        | 638      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "8.999999999999964\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "6.900000000000016\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-1.2000000000000157\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-43.000000000000014\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 236      |\n",
      "|    ep_rew_mean      | -177     |\n",
      "|    exploration_rate | 0.303    |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 9112     |\n",
      "|    total_timesteps  | 114822   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.376    |\n",
      "|    n_updates        | 648      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-33.50000000000011\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "2.8999999999999884\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-11.999999999999982\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-12.099999999999975\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 235      |\n",
      "|    ep_rew_mean      | -176     |\n",
      "|    exploration_rate | 0.298    |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 9252     |\n",
      "|    total_timesteps  | 115681   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 656      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "4.2000000000000135\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-10.999999999999996\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "10.300000000000017\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "37.79999999999995\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 233      |\n",
      "|    ep_rew_mean      | -175     |\n",
      "|    exploration_rate | 0.293    |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 9388     |\n",
      "|    total_timesteps  | 116501   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 665      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-19.09999999999998\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-30.999999999999993\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "3.5000000000000218\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-6.6\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 232      |\n",
      "|    ep_rew_mean      | -165     |\n",
      "|    exploration_rate | 0.288    |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 9530     |\n",
      "|    total_timesteps  | 117332   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.404    |\n",
      "|    n_updates        | 673      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "28.799999999999947\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-31.60000000000001\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-11.399999999999984\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-534.9999999999999\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 231      |\n",
      "|    ep_rew_mean      | -155     |\n",
      "|    exploration_rate | 0.283    |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 9658     |\n",
      "|    total_timesteps  | 118097   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 680      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-723.8\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-372.0999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-389.19999999999993\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-879.8\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 229      |\n",
      "|    ep_rew_mean      | -162     |\n",
      "|    exploration_rate | 0.279    |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 9759     |\n",
      "|    total_timesteps  | 118748   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 3.38     |\n",
      "|    n_updates        | 687      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-25.600000000000087\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "43.999999999999964\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-14.299999999999976\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "4.599999999999964\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 231      |\n",
      "|    ep_rew_mean      | -140     |\n",
      "|    exploration_rate | 0.273    |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 9903     |\n",
      "|    total_timesteps  | 119740   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0889   |\n",
      "|    n_updates        | 697      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-11.09999999999997\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "3.899999999999965\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "33.9999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-13.40000000000002\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 232      |\n",
      "|    ep_rew_mean      | -124     |\n",
      "|    exploration_rate | 0.267    |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 10044    |\n",
      "|    total_timesteps  | 120788   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.378    |\n",
      "|    n_updates        | 707      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "11.499999999999961\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "5.800000000000008\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-0.099999999999973\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "13.699999999999942\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 233      |\n",
      "|    ep_rew_mean      | -123     |\n",
      "|    exploration_rate | 0.26     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10181    |\n",
      "|    total_timesteps  | 121894   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0745   |\n",
      "|    n_updates        | 718      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "2.1999999999999114\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "18.699999999999996\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "6.999999999999941\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "7.899999999999994\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 234      |\n",
      "|    ep_rew_mean      | -123     |\n",
      "|    exploration_rate | 0.253    |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10323    |\n",
      "|    total_timesteps  | 123001   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0937   |\n",
      "|    n_updates        | 730      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "40.69999999999992\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-48.60000000000005\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "42.89999999999991\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "16.39999999999992\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 235      |\n",
      "|    ep_rew_mean      | -122     |\n",
      "|    exploration_rate | 0.246    |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10460    |\n",
      "|    total_timesteps  | 124171   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0864   |\n",
      "|    n_updates        | 741      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-8.399999999999974\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-409.6\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-704.4999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-218.79999999999959\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 236      |\n",
      "|    ep_rew_mean      | -135     |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10586    |\n",
      "|    total_timesteps  | 125208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.29     |\n",
      "|    n_updates        | 752      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "32.49999999999992\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-20.600000000000087\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "14.899999999999979\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-13.099999999999989\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 239      |\n",
      "|    ep_rew_mean      | -135     |\n",
      "|    exploration_rate | 0.233    |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10722    |\n",
      "|    total_timesteps  | 126342   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.421    |\n",
      "|    n_updates        | 763      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-39.800000000000146\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "18.59999999999998\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-27.20000000000004\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-11.700000000000003\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 241      |\n",
      "|    ep_rew_mean      | -116     |\n",
      "|    exploration_rate | 0.226    |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 10864    |\n",
      "|    total_timesteps  | 127461   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0848   |\n",
      "|    n_updates        | 774      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-20.20000000000003\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-12.999999999999977\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-7.899999999999977\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "40.699999999999946\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 242      |\n",
      "|    ep_rew_mean      | -115     |\n",
      "|    exploration_rate | 0.219    |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11001    |\n",
      "|    total_timesteps  | 128573   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0786   |\n",
      "|    n_updates        | 785      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "3.8999999999999764\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-23.100000000000016\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "2.5000000000000098\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "37.59999999999998\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 241      |\n",
      "|    ep_rew_mean      | -114     |\n",
      "|    exploration_rate | 0.213    |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11139    |\n",
      "|    total_timesteps  | 129591   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.114    |\n",
      "|    n_updates        | 795      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-1218.9999999999977\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "30.199999999999918\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-10.000000000000034\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-12.699999999999969\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 244      |\n",
      "|    ep_rew_mean      | -112     |\n",
      "|    exploration_rate | 0.207    |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11280    |\n",
      "|    total_timesteps  | 130679   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0721   |\n",
      "|    n_updates        | 806      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "15.6999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "41.29999999999992\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "20.999999999999957\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "48.69999999999996\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 246      |\n",
      "|    ep_rew_mean      | -98.1    |\n",
      "|    exploration_rate | 0.2      |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11418    |\n",
      "|    total_timesteps  | 131766   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0776   |\n",
      "|    n_updates        | 817      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-22.19999999999998\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "36.39999999999996\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "33.09999999999994\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "20.30000000000002\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 246      |\n",
      "|    ep_rew_mean      | -96.8    |\n",
      "|    exploration_rate | 0.194    |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11560    |\n",
      "|    total_timesteps  | 132801   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.703    |\n",
      "|    n_updates        | 828      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "13.199999999999925\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "56.39999999999996\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "4.100000000000001\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "10.799999999999944\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 247      |\n",
      "|    ep_rew_mean      | -96.4    |\n",
      "|    exploration_rate | 0.187    |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11703    |\n",
      "|    total_timesteps  | 133901   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0909   |\n",
      "|    n_updates        | 839      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-34.50000000000005\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-49.50000000000021\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-1095.1999999999998\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-749.5999999999999\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 247      |\n",
      "|    ep_rew_mean      | -116     |\n",
      "|    exploration_rate | 0.181    |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11826    |\n",
      "|    total_timesteps  | 134894   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 2.79     |\n",
      "|    n_updates        | 848      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-965.0999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-599.5000000000003\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-54.700000000000024\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-16.399999999999988\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 244      |\n",
      "|    ep_rew_mean      | -120     |\n",
      "|    exploration_rate | 0.177    |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 11958    |\n",
      "|    total_timesteps  | 135596   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.83     |\n",
      "|    n_updates        | 855      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-5.399999999999984\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "35.19999999999998\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "29.499999999999915\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "36.19999999999998\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 246      |\n",
      "|    ep_rew_mean      | -94.2    |\n",
      "|    exploration_rate | 0.171    |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12100    |\n",
      "|    total_timesteps  | 136563   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.376    |\n",
      "|    n_updates        | 865      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-2.2999999999999785\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-31.499999999999993\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-4.400000000000055\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-15.500000000000004\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 246      |\n",
      "|    ep_rew_mean      | -95.2    |\n",
      "|    exploration_rate | 0.165    |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12238    |\n",
      "|    total_timesteps  | 137552   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0477   |\n",
      "|    n_updates        | 875      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "22.69999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "16.899999999999892\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-11.499999999999986\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-13.100000000000039\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 247      |\n",
      "|    ep_rew_mean      | -95.4    |\n",
      "|    exploration_rate | 0.158    |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12381    |\n",
      "|    total_timesteps  | 138601   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0606   |\n",
      "|    n_updates        | 886      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "33.499999999999936\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "6.09999999999998\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-22.40000000000009\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-42.00000000000012\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 248      |\n",
      "|    ep_rew_mean      | -95.4    |\n",
      "|    exploration_rate | 0.152    |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12516    |\n",
      "|    total_timesteps  | 139589   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0941   |\n",
      "|    n_updates        | 895      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-50.0000000000001\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-0.100000000000043\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-29.700000000000017\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-12.999999999999957\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 248      |\n",
      "|    ep_rew_mean      | -95.8    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12653    |\n",
      "|    total_timesteps  | 140527   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.339    |\n",
      "|    n_updates        | 905      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-60.10000000000008\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "17.199999999999932\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-26.999999999999986\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-56.70000000000009\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 251      |\n",
      "|    ep_rew_mean      | -97.7    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12796    |\n",
      "|    total_timesteps  | 141576   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0728   |\n",
      "|    n_updates        | 915      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-16.40000000000004\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "40.9999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-17.499999999999993\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-25.50000000000005\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 252      |\n",
      "|    ep_rew_mean      | -97.3    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 12937    |\n",
      "|    total_timesteps  | 142527   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.401    |\n",
      "|    n_updates        | 925      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "38.8\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "10.500000000000025\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "47.39999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-2.39999999999997\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 255      |\n",
      "|    ep_rew_mean      | -91.1    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13078    |\n",
      "|    total_timesteps  | 143576   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0633   |\n",
      "|    n_updates        | 935      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-17.89999999999997\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "43.499999999999936\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "12.399999999999938\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-4.500000000000009\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 259      |\n",
      "|    ep_rew_mean      | -67.6    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13219    |\n",
      "|    total_timesteps  | 144601   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.359    |\n",
      "|    n_updates        | 946      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-16.999999999999986\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-20.10000000000005\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "13.599999999999936\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-2.8000000000000185\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 259      |\n",
      "|    ep_rew_mean      | -68      |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13360    |\n",
      "|    total_timesteps  | 145648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.051    |\n",
      "|    n_updates        | 956      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "11.399999999999945\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-19.500000000000096\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-317.29999999999995\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "28.89999999999994\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 258      |\n",
      "|    ep_rew_mean      | -71.1    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13495    |\n",
      "|    total_timesteps  | 146622   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 966      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "23.799999999999933\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-40.70000000000006\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-47.50000000000015\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-338.5000000000001\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 258      |\n",
      "|    ep_rew_mean      | -75.4    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13632    |\n",
      "|    total_timesteps  | 147648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0544   |\n",
      "|    n_updates        | 976      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-1029.6999999999998\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-869.0999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-869.3999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-909.3\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 255      |\n",
      "|    ep_rew_mean      | -112     |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13735    |\n",
      "|    total_timesteps  | 148465   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 4.31     |\n",
      "|    n_updates        | 984      |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-794.4999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-18.200000000000053\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-35.60000000000004\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "3.8999999999999595\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 253      |\n",
      "|    ep_rew_mean      | -121     |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 13866    |\n",
      "|    total_timesteps  | 149434   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0669   |\n",
      "|    n_updates        | 994      |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-22.400000000000077\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-3.0000000000000897\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-17.299999999999986\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "23.999999999999943\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 253      |\n",
      "|    ep_rew_mean      | -108     |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14008    |\n",
      "|    total_timesteps  | 150494   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0972   |\n",
      "|    n_updates        | 1004     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-21.500000000000014\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "6.999999999999934\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "42.89999999999997\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-55.40000000000007\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 252      |\n",
      "|    ep_rew_mean      | -109     |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14148    |\n",
      "|    total_timesteps  | 151530   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.372    |\n",
      "|    n_updates        | 1015     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "17.500000000000007\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-15.299999999999965\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-7.899999999999967\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "19.59999999999991\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 251      |\n",
      "|    ep_rew_mean      | -108     |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14291    |\n",
      "|    total_timesteps  | 152596   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0568   |\n",
      "|    n_updates        | 1025     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-43.000000000000036\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "34.19999999999997\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-16.500000000000036\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-48.80000000000008\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -109     |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14433    |\n",
      "|    total_timesteps  | 153622   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0791   |\n",
      "|    n_updates        | 1036     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "10.299999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "0.6999999999999932\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-15.800000000000013\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-6.599999999999966\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 251      |\n",
      "|    ep_rew_mean      | -109     |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14576    |\n",
      "|    total_timesteps  | 154678   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.388    |\n",
      "|    n_updates        | 1046     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-8.80000000000001\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-39.600000000000094\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-41.40000000000002\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "14.899999999999984\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -97.7    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14721    |\n",
      "|    total_timesteps  | 155701   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.061    |\n",
      "|    n_updates        | 1057     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "29.099999999999923\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "15.399999999999979\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "0.3999999999999506\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "3.3000000000000256\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -98.7    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 14862    |\n",
      "|    total_timesteps  | 156745   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0623   |\n",
      "|    n_updates        | 1067     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "10.599999999999907\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-26.200000000000053\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-8.199999999999973\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-25.500000000000135\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -99.8    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15002    |\n",
      "|    total_timesteps  | 157790   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0552   |\n",
      "|    n_updates        | 1077     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-0.10000000000001652\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "23.899999999999963\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "21.400000000000006\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-3.4000000000000647\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 249      |\n",
      "|    ep_rew_mean      | -100     |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15144    |\n",
      "|    total_timesteps  | 158801   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.381    |\n",
      "|    n_updates        | 1088     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "21.60000000000001\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "17.199999999999896\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-41.20000000000002\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-38.60000000000008\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 249      |\n",
      "|    ep_rew_mean      | -81.5    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15282    |\n",
      "|    total_timesteps  | 159806   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0826   |\n",
      "|    n_updates        | 1098     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "23.699999999999974\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-14.30000000000001\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-980.9999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-836.6999999999999\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 252      |\n",
      "|    ep_rew_mean      | -83.2    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15408    |\n",
      "|    total_timesteps  | 160754   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.29     |\n",
      "|    n_updates        | 1107     |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-859.4\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-725.5000000000011\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-24.000000000000103\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "19.30000000000004\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 252      |\n",
      "|    ep_rew_mean      | -99.9    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15541    |\n",
      "|    total_timesteps  | 161772   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0698   |\n",
      "|    n_updates        | 1117     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "7.699999999999915\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-21.300000000000004\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-6.799999999999994\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "8.300000000000026\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 253      |\n",
      "|    ep_rew_mean      | -99.5    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15681    |\n",
      "|    total_timesteps  | 162838   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.344    |\n",
      "|    n_updates        | 1128     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "15.599999999999945\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "10.099999999999994\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-47.80000000000004\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-0.09999999999997466\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 253      |\n",
      "|    ep_rew_mean      | -99.8    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15823    |\n",
      "|    total_timesteps  | 163901   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0571   |\n",
      "|    n_updates        | 1139     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "41.49999999999992\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-21.70000000000011\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-23.00000000000002\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "44.39999999999994\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 254      |\n",
      "|    ep_rew_mean      | -99.2    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 15963    |\n",
      "|    total_timesteps  | 164974   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.365    |\n",
      "|    n_updates        | 1149     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "44.49999999999997\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-0.39999999999998825\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "0.09999999999999165\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-23.99999999999997\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 254      |\n",
      "|    ep_rew_mean      | -98      |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16102    |\n",
      "|    total_timesteps  | 165921   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0782   |\n",
      "|    n_updates        | 1159     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "14.69999999999997\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-12.10000000000005\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-9.69999999999997\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "0.09999999999994386\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 252      |\n",
      "|    ep_rew_mean      | -97.1    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16244    |\n",
      "|    total_timesteps  | 166814   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0534   |\n",
      "|    n_updates        | 1168     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-23.40000000000007\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "2.3999999999999493\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "6.900000000000041\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-13.599999999999977\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 253      |\n",
      "|    ep_rew_mean      | -97.1    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16384    |\n",
      "|    total_timesteps  | 167826   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.371    |\n",
      "|    n_updates        | 1178     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "0.39999999999996483\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-44.40000000000007\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "5.399999999999924\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "24.199999999999967\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 252      |\n",
      "|    ep_rew_mean      | -98.2    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16523    |\n",
      "|    total_timesteps  | 168768   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.07     |\n",
      "|    n_updates        | 1187     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "7.899999999999973\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "25.99999999999998\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-25.499999999999996\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "16.89999999999999\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 252      |\n",
      "|    ep_rew_mean      | -98.3    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16665    |\n",
      "|    total_timesteps  | 169801   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0707   |\n",
      "|    n_updates        | 1198     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-21.40000000000006\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "29.59999999999996\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-25.5000000000001\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "10.799999999999933\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 252      |\n",
      "|    ep_rew_mean      | -98.1    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16808    |\n",
      "|    total_timesteps  | 170801   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0599   |\n",
      "|    n_updates        | 1208     |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "19.099999999999977\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-24.40000000000004\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "23.900000000000002\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-12.700000000000017\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 252      |\n",
      "|    ep_rew_mean      | -95.1    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 16944    |\n",
      "|    total_timesteps  | 171772   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0605   |\n",
      "|    n_updates        | 1217     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "1.8999999999999773\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-552.8\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-1039.8999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-896.3999999999999\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 249      |\n",
      "|    ep_rew_mean      | -116     |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17065    |\n",
      "|    total_timesteps  | 172577   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 3.09     |\n",
      "|    n_updates        | 1225     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-531.5000000000002\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "2.499999999999951\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-43.10000000000003\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "11.900000000000006\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -85      |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17206    |\n",
      "|    total_timesteps  | 173453   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0624   |\n",
      "|    n_updates        | 1234     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-45.200000000000074\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "4.199999999999935\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-25.60000000000005\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-5.899999999999979\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 250      |\n",
      "|    ep_rew_mean      | -77.4    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17344    |\n",
      "|    total_timesteps  | 174410   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.651    |\n",
      "|    n_updates        | 1244     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-20.600000000000023\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "21.099999999999966\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "24.1\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "6.099999999999996\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 249      |\n",
      "|    ep_rew_mean      | -76.9    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17484    |\n",
      "|    total_timesteps  | 175420   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.062    |\n",
      "|    n_updates        | 1254     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "26.49999999999998\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-32.700000000000024\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-66.4\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-11.600000000000005\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 248      |\n",
      "|    ep_rew_mean      | -77.5    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 10       |\n",
      "|    time_elapsed     | 17626    |\n",
      "|    total_timesteps  | 176301   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.29     |\n",
      "|    n_updates        | 1263     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-43.80000000000002\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-1.900000000000063\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-28.10000000000003\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-12.899999999999977\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 246      |\n",
      "|    ep_rew_mean      | -78.5    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 17767    |\n",
      "|    total_timesteps  | 177190   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.35     |\n",
      "|    n_updates        | 1271     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "18.900000000000016\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-18.19999999999998\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "3.0000000000000164\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-33.50000000000003\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 245      |\n",
      "|    ep_rew_mean      | -78      |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 17909    |\n",
      "|    total_timesteps  | 178088   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.403    |\n",
      "|    n_updates        | 1280     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-39.40000000000007\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-30.09999999999998\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-11.100000000000001\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "2.2000000000000277\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 243      |\n",
      "|    ep_rew_mean      | -78.7    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 18047    |\n",
      "|    total_timesteps  | 178940   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.366    |\n",
      "|    n_updates        | 1289     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-34.00000000000005\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-21.999999999999986\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-0.7000000000000477\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-49.30000000000005\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 241      |\n",
      "|    ep_rew_mean      | -79      |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 18190    |\n",
      "|    total_timesteps  | 179801   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0536   |\n",
      "|    n_updates        | 1298     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-34.70000000000002\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-3.0000000000000537\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-31.30000000000001\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-411.49999999999994\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 238      |\n",
      "|    ep_rew_mean      | -84.4    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 18331    |\n",
      "|    total_timesteps  | 180574   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.658    |\n",
      "|    n_updates        | 1305     |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-560.8\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-300.5999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-919.1999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-465.2\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 234      |\n",
      "|    ep_rew_mean      | -106     |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 18445    |\n",
      "|    total_timesteps  | 181182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 5.76     |\n",
      "|    n_updates        | 1311     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-18.399999999999995\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-10.39999999999998\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-56.7000000000001\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "5.999999999999938\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 232      |\n",
      "|    ep_rew_mean      | -107     |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 18588    |\n",
      "|    total_timesteps  | 182032   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0636   |\n",
      "|    n_updates        | 1320     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-27.700000000000003\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-51.30000000000003\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-33.50000000000002\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-32.000000000000014\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 230      |\n",
      "|    ep_rew_mean      | -108     |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 18730    |\n",
      "|    total_timesteps  | 182760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.648    |\n",
      "|    n_updates        | 1327     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-25.09999999999998\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-15.79999999999998\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-70.40000000000008\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-38.20000000000005\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 230      |\n",
      "|    ep_rew_mean      | -92.1    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 18871    |\n",
      "|    total_timesteps  | 183773   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.686    |\n",
      "|    n_updates        | 1337     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-29.400000000000006\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "18.49999999999993\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-35.100000000000016\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "37.7\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 230      |\n",
      "|    ep_rew_mean      | -76.4    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 19012    |\n",
      "|    total_timesteps  | 184799   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.365    |\n",
      "|    n_updates        | 1347     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-58.00000000000008\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "18.19999999999996\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "23.599999999999916\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-1.3999999999999684\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 230      |\n",
      "|    ep_rew_mean      | -76.5    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 19152    |\n",
      "|    total_timesteps  | 185796   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0943   |\n",
      "|    n_updates        | 1357     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "23.49999999999995\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-8.19999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "23.099999999999966\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-5.200000000000037\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 229      |\n",
      "|    ep_rew_mean      | -75.8    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 19294    |\n",
      "|    total_timesteps  | 186812   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 1368     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "11.700000000000024\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-29.900000000000013\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "12.49999999999998\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-63.70000000000006\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 229      |\n",
      "|    ep_rew_mean      | -76.9    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 19435    |\n",
      "|    total_timesteps  | 187871   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.337    |\n",
      "|    n_updates        | 1378     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "2.4000000000000155\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-8.100000000000025\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-92.4999999999999\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-330.0\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 230      |\n",
      "|    ep_rew_mean      | -81.2    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 19571    |\n",
      "|    total_timesteps  | 188875   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.426    |\n",
      "|    n_updates        | 1388     |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-872.3\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "5.899999999999892\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-29.800000000000026\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "11.199999999999982\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 231      |\n",
      "|    ep_rew_mean      | -89.7    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 19701    |\n",
      "|    total_timesteps  | 189865   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0599   |\n",
      "|    n_updates        | 1398     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-22.400000000000006\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "23.59999999999995\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-31.300000000000054\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-5.999999999999984\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 231      |\n",
      "|    ep_rew_mean      | -89.8    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 19842    |\n",
      "|    total_timesteps  | 190922   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.361    |\n",
      "|    n_updates        | 1409     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "28.09999999999993\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-28.100000000000033\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "17.799999999999926\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-34.3000000000001\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 232      |\n",
      "|    ep_rew_mean      | -89.8    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 19985    |\n",
      "|    total_timesteps  | 191962   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 1419     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-11.299999999999963\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-17.49999999999998\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "2.3999999999999893\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "11.399999999999954\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 232      |\n",
      "|    ep_rew_mean      | -90.2    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 20130    |\n",
      "|    total_timesteps  | 193001   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.339    |\n",
      "|    n_updates        | 1430     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-35.100000000000016\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-33.600000000000115\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-35.500000000000014\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-26.90000000000009\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 232      |\n",
      "|    ep_rew_mean      | -91.3    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 20270    |\n",
      "|    total_timesteps  | 193971   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 1439     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-40.80000000000005\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-2.099999999999973\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-394.4000000000006\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-1259.6\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 232      |\n",
      "|    ep_rew_mean      | -108     |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 20402    |\n",
      "|    total_timesteps  | 194994   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.961    |\n",
      "|    n_updates        | 1449     |\n",
      "----------------------------------\n",
      "End episode, cumulative Reward:\n",
      "-1277.6999999999998\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-652.5999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-12.399999999999977\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "45.799999999999976\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 233      |\n",
      "|    ep_rew_mean      | -103     |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 20528    |\n",
      "|    total_timesteps  | 195888   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.415    |\n",
      "|    n_updates        | 1458     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-37.0\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-4.099999999999979\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "17.199999999999918\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "2.2999999999999545\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 235      |\n",
      "|    ep_rew_mean      | -97.1    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 20669    |\n",
      "|    total_timesteps  | 196944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.39     |\n",
      "|    n_updates        | 1469     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "29.899999999999906\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-25.199999999999996\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "0.8999999999999344\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-41.00000000000002\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 236      |\n",
      "|    ep_rew_mean      | -96.7    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 20810    |\n",
      "|    total_timesteps  | 198045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.353    |\n",
      "|    n_updates        | 1480     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "-29.700000000000067\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "16.399999999999984\n",
      "(1000, 600, 3)\n",
      "End episode, cumulative Reward:\n",
      "-8.1\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "-24.400000000000084\n",
      "(1000, 600, 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 237      |\n",
      "|    ep_rew_mean      | -97.4    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 9        |\n",
      "|    time_elapsed     | 20947    |\n",
      "|    total_timesteps  | 199139   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.348    |\n",
      "|    n_updates        | 1491     |\n",
      "----------------------------------\n",
      "Request Timed Out, cumulative Reward:\n",
      "21.199999999999967\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "11.899999999999999\n",
      "(1000, 600, 3)\n",
      "Request Timed Out, cumulative Reward:\n",
      "19.799999999999926\n",
      "(1000, 600, 3)\n",
      "(1000, 600, 3)\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Request Timed Out, cumulative Reward:\n",
      "-14.400000000000006\n",
      "Action:\n",
      "1\n",
      "########################Reward Obtained:\n",
      "-11\n",
      "(1000, 600, 3)\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Request Timed Out, cumulative Reward:\n",
      "-52.8000000000001\n",
      "Action:\n",
      "1\n",
      "########################Reward Obtained:\n",
      "-11\n",
      "(1000, 600, 3)\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Request Timed Out, cumulative Reward:\n",
      "6.600000000000028\n",
      "Action:\n",
      "1\n",
      "########################Reward Obtained:\n",
      "-11\n",
      "(1000, 600, 3)\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Request Timed Out, cumulative Reward:\n",
      "10.699999999999848\n",
      "Action:\n",
      "1\n",
      "########################Reward Obtained:\n",
      "-11\n",
      "(1000, 600, 3)\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f4nyt\\anaconda3\\envs\\RL\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test2 is the successful one (but still just spams enter key)\n",
    "#LOADING MODEL FROM ZIP\n",
    "#loaded_model = DQN.load(\"DQNEveon_test2\")\n",
    "loaded_model = DQN.load(\"DQNEveon_testing_surface_250222\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(1000, 600, 3)\n",
      "(1000, 600, 3)\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "2\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "3\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "0\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n",
      "Action:\n",
      "1\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f4nyt\\anaconda3\\envs\\RL\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "nodeList, linkList = createTestTopology()\n",
    "\n",
    "#changed to only have 1 request per episode\n",
    "#from 6 originally\n",
    "requestList = generateRequests(nodeList, 10)\n",
    "\n",
    "user = User()\n",
    "eveon = game_gym(nodeList, linkList, requestList, user)\n",
    "\n",
    "check_env(eveon, warn=True)\n",
    "\n",
    "# THIS IS THE TESTING LOOP OF THE AGENT PLAYING THE GAME\n",
    "obs = eveon.reset()\n",
    "while True :\n",
    "    #trying to test if deterministic true or false changes model actions\n",
    "    action, states_ = loaded_model.predict(obs, deterministic=False)\n",
    "    # action = 6\n",
    "    obs, rewards, dones, info = eveon.step(action)\n",
    "    \n",
    "    print(\"Action:\")\n",
    "    print(action)\n",
    "    #time.sleep(1)\n",
    "    #clear_output(wait=True)\n",
    "\n",
    "\n",
    "    if dones == True:\n",
    "        #debug print\n",
    "        print(\"########################Reward Obtained:\")\n",
    "        print(eveon.reward)\n",
    "        # with open('info.json', 'w') as outfile:\n",
    "        #     json.dump(info, outfile)\n",
    "\n",
    "        eveon.reset()\n",
    "\n",
    "    eveon.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test main function\n",
    "nodeList, linkList = createTestTopology()\n",
    "requestList = generateRequests(nodeList, 6)\n",
    "\n",
    "user = User()\n",
    "eveon = game_gym(nodeList, linkList, requestList, user)\n",
    "\n",
    "check_env(eveon, warn=True)\n",
    "\n",
    "#defining the agent\n",
    "model = DQN('MlpPolicy', eveon, verbose=1, buffer_size=100, device='cuda')\n",
    "\n",
    "screen = eveon.render()\n",
    "#storing episode_durations during training to plot them\n",
    "#creating empty list to store\n",
    "#adding plot to check the training process?\n",
    "episode_durations = []\n",
    "timestep = 0\n",
    "\n",
    "\n",
    "#trying the double nested for loop\n",
    "\n",
    "for episode in range(100):\n",
    "\n",
    "#resets the environment\n",
    "obs = eveon.reset()\n",
    "\n",
    "#nested for loop iterate over time step\n",
    "for timesetp in count():\n",
    "\n",
    "    action, states_ = model.predict(obs, deterministic=True)\n",
    "    # action = 6\n",
    "    \n",
    "    obs, rewards, dones, info = eveon.step(action)\n",
    "    \n",
    "\n",
    "    print(action)\n",
    "    \n",
    "    #this only runs when the agent actually competed the level\n",
    "    if dones == True:\n",
    "        #debug print\n",
    "        print(\"########################Reward Obtained:\")\n",
    "        print(eveon.reward)\n",
    "\n",
    "        episode_durations.append(timestep)\n",
    "        plot(episode_durations, 100)\n",
    "        \n",
    "        # with open('info.json', 'w') as outfile:\n",
    "        #     json.dump(info, outfile)\n",
    "        timestep += 1\n",
    "        eveon.reset()\n",
    "\n",
    "    eveon.render()\n",
    "\n",
    "    screen = eveon.render('rgb_array')\n",
    "    plt.figure()\n",
    "    plt.imshow(screen)\n",
    "    plt.title('test screen')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40b93cbb1699659d2cb0e714698cbe72f80d4ea3079150298ec50c78e4aa7ede"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('RL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
